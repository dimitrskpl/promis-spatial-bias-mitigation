{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed for preprocessing the CRIME, LAR datasets, training XGB on CRIME, generating predictions, and creating spatial partitionings. Below are the steps to follow along with the values that should be set before running the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the CRIME dataset:\n",
    "\n",
    "    * Download Crime Data from 2010 to 2019: <https://data.lacity.org/Public-Safety/Crime-Data-from-2010-to-2019/63jg-8b9z>\n",
    "    * File Name: Ensure the file is saved as Crime_Data_from_2010_to_2019.csv.\n",
    "\n",
    "2. Download the LAR dataset:\n",
    "\n",
    "    a. Modified LAR Data:\n",
    "\n",
    "    * Download from: CFPB Modified LAR Data 2021 <https://ffiec.cfpb.gov/data-publication/modified-lar/2021>\n",
    "\n",
    "    * Select the year 2021.\n",
    "    * Enter B4TYDEB6GKMZO031MB27 as the Legal Entity Identifier (LEI) for Bank of America.\n",
    "    * Opt to \"Include File Header.\"\n",
    "    * Click on \"Download Modified LAR with Header.\"\n",
    "    * File Name: Ensure the file is saved as B4TYDEB6GKMZO031MB27_header.csv.\n",
    "\n",
    "    b. Census Gazetteer Data:\n",
    "\n",
    "    * Download from: Census Gazetteer Files 2021 <https://www.census.gov/geographies/reference-files/time-series/geo/gazetteer-files.2021.html>\n",
    "\n",
    "    * Locate the \"Census Tracts\" section.\n",
    "    * Click on \"Download the National Census Tracts Gazetteer Files.\"\n",
    "    * Unzip it.\n",
    "    * File Name: Ensure the file is saved as 2021_Gaz_tracts_national.txt.\n",
    "\n",
    "3. Define File Paths and Labels\n",
    "\n",
    "Although the paths to the neccessary read/write folders are set to default values, before running the processing steps, you may modify the following paths in the second cell.\n",
    "To use the default dataset path value (recommended), create a folder named *data* and a subfolder inside *data* named *datasets* at the parent level and place the following files in *../data/datasets/*:\n",
    "* *Crime_Data_from_2010_to_2019.csv*\n",
    "* *B4TYDEB6GKMZO031MB27_header.csv* \n",
    "* *2021_Gaz_tracts_national.txt*\n",
    "\n",
    "\n",
    "**Paths**\n",
    "* base_path: The main directory where all dataset-related files are stored. The default value is *../data/*\n",
    "* datasets_base_path: Path where the raw datasets are stored. The default value is *base_path/datasets/*\n",
    "* predictions_base_path: Path where model predictions are saved. The default value is *base_path/predictions/*\n",
    "* preprocess_path: Path where true labels are stored. The default value is *base_path/preprocess/*\n",
    "* clf_base_path: Path where trained machine learning models are saved. The default value is *base_path/clf/*\n",
    "* partioning_base_path: Path where partitioning results are saved. The default value is *base_path/partitionings/*\n",
    "* crime_data_filename: The path to the crime dataset. The default value is *base_path/datasets/Crime_Data_from_2010_to_2019.csv.*\n",
    "* lar_data_filename: The path to the crime dataset. The default value is *base_path/datasets/B4TYDEB6GKMZO031MB27_header.csv.*\n",
    "* census_gazetteer_data_filename: The path to the crime dataset. The default value is *base_path/datasets/2021_Gaz_tracts_national.txt.*\n",
    "\n",
    "3. The dataset should be placed in the datasets_base_path folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.xgb_crime import crime_xgb_train_predict\n",
    "from utils.preprocess import proprocess_crime, preprocess_lar\n",
    "from utils.create_partitioning import create_kmeans_partioning, create_grid_partitioning\n",
    "from utils.create_unfair_world import create_unfair_world\n",
    "from utils.results_names_utils import combine_world_info, get_train_val_test_paths\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../data/\"\n",
    "datasets_base_path = f\"{base_path}datasets/\"\n",
    "preprocess_base_path = f\"{base_path}preprocess/\"\n",
    "predictions_base_path = f\"{base_path}predictions/\"\n",
    "clf_base_path = f\"{base_path}clf/\"\n",
    "partioning_base_path = f\"{base_path}partitionings/\"\n",
    "crime_data_filename = f\"{datasets_base_path}Crime_Data_from_2010_to_2019.csv\"\n",
    "lar_data_filename = f\"{datasets_base_path}B4TYDEB6GKMZO031MB27_header.csv\"\n",
    "census_gazetteer_data_filename = f\"{datasets_base_path}2021_Gaz_tracts_national.txt\"\n",
    "\n",
    "for dir in [datasets_base_path, predictions_base_path, clf_base_path, partioning_base_path, preprocess_base_path]:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set - Combine the neccessary paths, labels descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_dataset_name = \"crime\"\n",
    "lar_dataset_name = \"lar\"\n",
    "\n",
    "crime_xgb_clf_name = \"xgb_crime\"\n",
    "crime_xgb_predictions_name = f\"pred_{crime_xgb_clf_name}\"\n",
    "crime_xgb_train_predictions_filename = f\"{predictions_base_path}train_{crime_xgb_predictions_name}.csv\"\n",
    "crime_xgb_val_predictions_filename = f\"{predictions_base_path}val_{crime_xgb_predictions_name}.csv\"\n",
    "crime_xgb_test_predictions_filename = f\"{predictions_base_path}test_{crime_xgb_predictions_name}.csv\"\n",
    "clf_xgb_filename = f\"{clf_base_path}{crime_xgb_clf_name}.joblib\"\n",
    "\n",
    "lar_labels_filename = f\"{preprocess_base_path}lar.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lar_df = preprocess_lar(lar_data_filename, census_gazetteer_data_filename, preprocess_base_path)\n",
    "print(f\"LAR total rows: {lar_df.shape[0]}\")\n",
    "print(f\"LAR total positive rows: {lar_df['label'].sum()}\")\n",
    "lar_pr = lar_df['label'].sum() / lar_df.shape[0]\n",
    "print(f\"LAR positive rate: {lar_pr:.2f}\")\n",
    "display(lar_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_crime, X_val_crime, X_test_crime, y_train_crime, y_val_crime, y_test_crime = proprocess_crime(crime_data_filename, preprocess_base_path)\n",
    "\n",
    "crime_total_positives =  y_train_crime.sum() + y_val_crime.sum() + y_test_crime.sum() \n",
    "crime_total_rows = y_train_crime.shape[0] + y_val_crime.shape[0] + y_test_crime.shape[0]\n",
    "crime_total_pr = crime_total_positives / crime_total_rows\n",
    "\n",
    "print(f\"Crime total rows: {crime_total_rows}\")\n",
    "print(f\"Crime total positives: {crime_total_positives}\")\n",
    "print(f\"Crime total (true) positive rate: {crime_total_pr:.2f}\")\n",
    "\n",
    "print(f\"X_train_crime.shape: {X_train_crime.shape}\")\n",
    "print(f\"X_val_crime.shape: {X_val_crime.shape}\")\n",
    "print(f\"X_test_crime.shape: {X_test_crime.shape}\")\n",
    "print(f\"y_train_crime.shape: {y_train_crime.shape}\")\n",
    "print(f\"y_val_crime.shape: {y_val_crime.shape}\")\n",
    "print(f\"y_test_crime.shape: {y_test_crime.shape}\")\n",
    "\n",
    "display(X_train_crime.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step trains XGBoost on the crime dataset and saves the pretrained model, its predictions and probabilities.\n",
    "y_train_pred, y_test_pred, y_val_pred = crime_xgb_train_predict(\n",
    "    X_train=X_train_crime,\n",
    "    X_val=X_val_crime,\n",
    "    X_test=X_test_crime,\n",
    "    y_train=y_train_crime,\n",
    "    crime_train_predictions_filename=crime_xgb_train_predictions_filename,\n",
    "    crime_val_predictions_filename=crime_xgb_val_predictions_filename,\n",
    "    crime_test_predictions_filename=crime_xgb_test_predictions_filename,\n",
    "    clf_filename=clf_xgb_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_y_train_pr = y_train_pred.sum() / y_train_pred.shape[0]\n",
    "crime_y_val_pr = y_val_pred.sum() / y_val_pred.shape[0]\n",
    "crime_y_test_pr = y_test_pred.sum() / y_test_pred.shape[0]\n",
    "print(f\"Positive rate in training predictions: {crime_y_train_pr:.2f}\")\n",
    "print(f\"Positive rate in validation predictions: {crime_y_val_pr:.2f}\")\n",
    "print(f\"Positive rate in test predictions: {crime_y_test_pr:.2f}\")\n",
    "\n",
    "crime_y_train_tpr = (y_train_pred & y_train_crime).sum() / y_train_crime.sum()\n",
    "crime_y_val_tpr = (y_val_pred & y_val_crime).sum() / y_val_crime.sum()\n",
    "crime_y_test_tpr = (y_test_pred & y_test_crime).sum() / y_test_crime.sum()\n",
    "print(f\"Crime true positive rate in training set: {crime_y_train_tpr:.2f}\")\n",
    "print(f\"Crime true positive rate in validation set: {crime_y_val_tpr:.2f}\")\n",
    "print(f\"Crime true positive rate in test set: {crime_y_test_tpr:.2f}\")\n",
    "\n",
    "crime_val_acc = (y_val_pred == y_val_crime).sum() / y_val_crime.shape[0]\n",
    "crime_test_acc = (y_test_pred == y_test_crime).sum() / y_test_crime.shape[0]\n",
    "print(f\"Crime validation accuracy: {crime_val_acc:.2f}\")\n",
    "print(f\"Crime test accuracy: {crime_test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Audit Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Overlapping Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the data into spatial clusters using the KMeans clustering method for the initial center and with increasing radii starting from each center generates overlapping clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides the crime data into spatial clusters \n",
    "\n",
    "overlapping = True\n",
    "k = 10\n",
    "radii = np.arange(0.01, 0.1, 0.03)\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=crime_xgb_train_predictions_filename,\n",
    "    val_with_loc_filename=crime_xgb_val_predictions_filename,\n",
    "    test_with_loc_filename=crime_xgb_test_predictions_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=crime_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    "    with_partitioning_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides the lar data into spatial clusters \n",
    "\n",
    "overlapping = True\n",
    "k = 100\n",
    "radii = np.arange(0.05, 1.51, 0.05)\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=lar_labels_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=lar_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Non-Overlapping Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* overlapping=False to ensure that each data point belongs to only one region.\n",
    "* Keep k=10 clusters.\n",
    "* radii=None since overlapping is disabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides the crime data into spatial non-overlapping clusters using the KMeans clustering method.\n",
    "overlapping = False\n",
    "k = 8\n",
    "radii = None\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=crime_xgb_train_predictions_filename,\n",
    "    val_with_loc_filename=crime_xgb_val_predictions_filename,\n",
    "    test_with_loc_filename=crime_xgb_test_predictions_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=crime_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    "    with_partitioning_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides the lar data into spatial non-overlapping clusters using the KMeans clustering method.\n",
    "\n",
    "overlapping = False\n",
    "k = 100\n",
    "radii = None\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=lar_labels_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=lar_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid with max rowsXcolumns = 5X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create partitionings with max 5X5 row and columns for CRIME\n",
    "create_grid_partitioning(\n",
    "    5,\n",
    "    5,\n",
    "    train_with_loc_filename=crime_xgb_train_predictions_filename,\n",
    "    val_with_loc_filename=crime_xgb_val_predictions_filename,\n",
    "    test_with_loc_filename=crime_xgb_test_predictions_filename,\n",
    "    partitioning_dir=partioning_base_path,\n",
    "    dataset_name=crime_dataset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create partitionings with max 5X5 row and columns for LAR\n",
    "create_grid_partitioning(\n",
    "    5,\n",
    "    5,\n",
    "    train_with_loc_filename=lar_labels_filename,\n",
    "    partitioning_dir=partioning_base_path,\n",
    "    dataset_name=lar_dataset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Crime Semi-Synthetic Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unfair By Design World Using Non-Overlapping Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name, partioning_type_name, overlap =  \"xgb\", \"non_overlap_k_8\", False\n",
    "res_desc_label, partioning_name, prediction_name = (\n",
    "    combine_world_info(crime_dataset_name, partioning_type_name, clf_name)\n",
    ")\n",
    "_, _, test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, crime_dataset_name\n",
    ")\n",
    "\n",
    "create_unfair_world(\n",
    "    rho=0.8,\n",
    "    test_path_info=test_path_info,\n",
    "    predictions_path=predictions_base_path,\n",
    "    partioning_name=partioning_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unfair By Design World Using Overlapping Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name, partioning_type_name, overlap =  \"xgb\", \"overlap_k_10_radii_4\", True\n",
    "res_desc_label, partioning_name, prediction_name = (\n",
    "    combine_world_info(crime_dataset_name, partioning_type_name, clf_name)\n",
    ")\n",
    "_, _, test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, crime_dataset_name\n",
    ")\n",
    "\n",
    "create_unfair_world(\n",
    "    rho=0.8,\n",
    "    test_path_info=test_path_info,\n",
    "    predictions_path=predictions_base_path,\n",
    "    partioning_name=partioning_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unfair By Design World Using Grid with max rowsXcolumns = 5X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name, partioning_type_name, overlap =  \"xgb\", \"5_x_5\", True\n",
    "res_desc_label, partioning_name, prediction_name = (\n",
    "    combine_world_info(crime_dataset_name, partioning_type_name, clf_name)\n",
    ")\n",
    "_, _,  test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, crime_dataset_name\n",
    ")\n",
    "\n",
    "create_unfair_world(\n",
    "    rho=0.8,\n",
    "    test_path_info=test_path_info,\n",
    "    predictions_path=predictions_base_path,\n",
    "    partioning_name=partioning_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promis_env",
   "language": "python",
   "name": "promis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

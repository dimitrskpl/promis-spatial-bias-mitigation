{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed for preprocessing the CRIME, LAR datasets, training XGB on CRIME, generating predictions, and creating spatial partitionings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paths to the neccessary read/write folders are set to the below values:\n",
    "\n",
    "**Paths**\n",
    "* base_path: The main directory where all dataset-related files are stored. The default value is *../data/*\n",
    "* datasets_base_path: Path where the raw datasets are stored. The default value is *base_path/datasets/*\n",
    "* predictions_base_path: Path where base model predictions are saved. The default value is *base_path/predictions/*\n",
    "* preprocess_path: Path where true labels are stored. The default value is *base_path/preprocess/*\n",
    "* clf_base_path: Path where trained machine learning models are saved. The default value is *base_path/clf/*\n",
    "* partioning_base_path: Path where partitioning results are saved. The default value is *base_path/partitionings/*\n",
    "* crime_data_filename: The path to the crime dataset. The default value is *base_path/datasets/Crime_Data_from_2010_to_2019.csv.*\n",
    "* lar_data_filename: The path to the crime dataset. The default value is *base_path/datasets/B4TYDEB6GKMZO031MB27_header.csv.*\n",
    "* census_gazetteer_data_filename: The path to the crime dataset. The default value is *base_path/datasets/2021_Gaz_tracts_national.txt.*\n",
    "\n",
    "**Produced Filenames Interpretation**\n",
    "* partitionings: \\<set name>\\_regions_\\<partitioning name>_\\<dataset name>.csv.\n",
    "* partitionings_ids: \\<set name>\\_regions_\\<partitioning name>_\\<dataset name>_ids.csv: same audit regions with partitionings in format where each id refers to a partitioning.\n",
    "* predictions: \\<set_name>_pred_<clf_name>_\\<dataset>\n",
    "where:\n",
    "\n",
    "* \\<set name>: train/val/set\n",
    "* \\<partitioning name>: \n",
    "    * 5_x_5 (ovelapping partitionings with max 5 row and max 5 columns i.e. 24 partitionings in toal excluding the 1x1), \n",
    "    * non_overlap_k_\\<n\\_regions> (non-overlapping regions produced by KMeans with <n\\_regions> centers), \n",
    "    * overlap_k_\\<n\\_regions>\\_radii_\\<n_radii> (overlapping regions starting from <n\\_regions> centers defined by KMeans and defing regions with max radius-boarders defined by the <n_radii> total radii).\n",
    "* \\<dataset name>: crime/lar\n",
    "* \\<clf_name>: xgb/dnn/semi\\_synthetic\\_regions_\\<partitioning_name> (the dnn is trained and saved in the src/experiments/dnn_exp.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.xgb_crime import crime_xgb_train_predict\n",
    "from utils.preprocess import proprocess_crime, preprocess_lar\n",
    "from utils.create_partitioning import create_kmeans_partioning, create_grid_partitioning\n",
    "from utils.create_unfair_world import create_unfair_world\n",
    "from utils.results_names_utils import combine_world_info, get_train_val_test_paths\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../data/\"\n",
    "datasets_base_path = f\"{base_path}datasets/\"\n",
    "preprocess_base_path = f\"{base_path}preprocess/\"\n",
    "predictions_base_path = f\"{base_path}predictions/\"\n",
    "clf_base_path = f\"{base_path}clf/\"\n",
    "partioning_base_path = f\"{base_path}partitionings/\"\n",
    "crime_data_filename = f\"{datasets_base_path}Crime_Data_from_2010_to_2019.csv\"\n",
    "lar_data_filename = f\"{datasets_base_path}B4TYDEB6GKMZO031MB27_header.csv\"\n",
    "census_gazetteer_data_filename = f\"{datasets_base_path}2021_Gaz_tracts_national.txt\"\n",
    "\n",
    "for dir in [datasets_base_path, predictions_base_path, clf_base_path, partioning_base_path, preprocess_base_path]:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip datasets files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [crime_data_filename, lar_data_filename, census_gazetteer_data_filename]:\n",
    "    zip_file = f\"{file}.zip\"\n",
    "    if os.path.exists(zip_file):\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(datasets_base_path)\n",
    "    else:\n",
    "        print(f\"File {zip_file} does not exist!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set - Combine the neccessary paths, labels descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_dataset_name = \"crime\"\n",
    "lar_dataset_name = \"lar\"\n",
    "\n",
    "crime_xgb_clf_name = \"xgb_crime\"\n",
    "crime_xgb_predictions_name = f\"pred_{crime_xgb_clf_name}\"\n",
    "crime_xgb_train_predictions_filename = f\"{predictions_base_path}train_{crime_xgb_predictions_name}.csv\"\n",
    "crime_xgb_val_predictions_filename = f\"{predictions_base_path}val_{crime_xgb_predictions_name}.csv\"\n",
    "crime_xgb_test_predictions_filename = f\"{predictions_base_path}test_{crime_xgb_predictions_name}.csv\"\n",
    "clf_xgb_filename = f\"{clf_base_path}{crime_xgb_clf_name}.joblib\"\n",
    "\n",
    "lar_labels_filename = f\"{preprocess_base_path}lar.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dimitriskyriakopoulos/Documents/ath/SpatiaFairness/PROMIS/promis-spatial-bias-mitigation/src/utils/preprocess.py:170: DtypeWarning: Columns (73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(lar_data_filename, delimiter=\"|\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAR total rows: 206418\n",
      "LAR total positive rows: 127286\n",
      "LAR positive rate: 0.62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.707050</td>\n",
       "      <td>-75.583242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>33.850356</td>\n",
       "      <td>-117.912135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>42.101448</td>\n",
       "      <td>-83.160279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>41.355900</td>\n",
       "      <td>-72.932356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>40.715907</td>\n",
       "      <td>-73.982094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label        lat         lon\n",
       "0       1  39.707050  -75.583242\n",
       "3       1  33.850356 -117.912135\n",
       "5       1  42.101448  -83.160279\n",
       "9       1  41.355900  -72.932356\n",
       "10      0  40.715907  -73.982094"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lar_df = preprocess_lar(lar_data_filename, census_gazetteer_data_filename, preprocess_base_path)\n",
    "print(f\"LAR total rows: {lar_df.shape[0]}\")\n",
    "print(f\"LAR total positive rows: {lar_df['label'].sum()}\")\n",
    "lar_pr = lar_df['label'].sum() / lar_df.shape[0]\n",
    "print(f\"LAR positive rate: {lar_pr:.2f}\")\n",
    "display(lar_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 427922 (60.00%)\n",
      "Validation size: 142641 (20.00%)\n",
      "Test size: 142641 (20.00%)\n",
      "Crime total rows: 713204\n",
      "Crime total positives: 204204\n",
      "Crime total (true) positive rate: 0.29\n",
      "X_train_crime.shape: (427922, 49)\n",
      "X_val_crime.shape: (142641, 49)\n",
      "X_test_crime.shape: (142641, 49)\n",
      "y_train_crime.shape: (427922,)\n",
      "y_val_crime.shape: (142641,)\n",
      "y_test_crime.shape: (142641,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Area_1</th>\n",
       "      <th>Area_2</th>\n",
       "      <th>Area_3</th>\n",
       "      <th>Area_4</th>\n",
       "      <th>Area_5</th>\n",
       "      <th>Area_6</th>\n",
       "      <th>Area_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Descent_K</th>\n",
       "      <th>Descent_L</th>\n",
       "      <th>Descent_O</th>\n",
       "      <th>Descent_P</th>\n",
       "      <th>Descent_S</th>\n",
       "      <th>Descent_U</th>\n",
       "      <th>Descent_V</th>\n",
       "      <th>Descent_W</th>\n",
       "      <th>Descent_X</th>\n",
       "      <th>Descent_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>34.0229</td>\n",
       "      <td>-118.2216</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33.9527</td>\n",
       "      <td>-118.3090</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1615</td>\n",
       "      <td>34.0812</td>\n",
       "      <td>-118.2032</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100</td>\n",
       "      <td>34.2103</td>\n",
       "      <td>-118.4529</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1140</td>\n",
       "      <td>33.9933</td>\n",
       "      <td>-118.2871</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TIME OCC      LAT       LON  Area_1  Area_2  Area_3  Area_4  Area_5  \\\n",
       "0       130  34.0229 -118.2216   False   False   False    True   False   \n",
       "1         1  33.9527 -118.3090   False   False   False   False   False   \n",
       "2      1615  34.0812 -118.2032   False   False   False    True   False   \n",
       "3      1100  34.2103 -118.4529   False   False   False   False   False   \n",
       "4      1140  33.9933 -118.2871   False   False   False   False   False   \n",
       "\n",
       "   Area_6  Area_7  ...  Descent_K  Descent_L  Descent_O  Descent_P  Descent_S  \\\n",
       "0   False   False  ...      False      False      False      False      False   \n",
       "1   False   False  ...      False      False      False      False      False   \n",
       "2   False   False  ...      False      False      False      False      False   \n",
       "3   False   False  ...      False      False      False      False      False   \n",
       "4   False   False  ...      False      False      False      False      False   \n",
       "\n",
       "   Descent_U  Descent_V  Descent_W  Descent_X  Descent_Z  \n",
       "0      False      False      False      False      False  \n",
       "1      False      False      False      False      False  \n",
       "2      False      False      False      False      False  \n",
       "3      False      False      False      False      False  \n",
       "4      False      False      False      False      False  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_crime, X_val_crime, X_test_crime, y_train_crime, y_val_crime, y_test_crime = proprocess_crime(crime_data_filename, preprocess_base_path)\n",
    "\n",
    "crime_total_positives =  y_train_crime.sum() + y_val_crime.sum() + y_test_crime.sum() \n",
    "crime_total_rows = y_train_crime.shape[0] + y_val_crime.shape[0] + y_test_crime.shape[0]\n",
    "crime_total_pr = crime_total_positives / crime_total_rows\n",
    "\n",
    "print(f\"Crime total rows: {crime_total_rows}\")\n",
    "print(f\"Crime total positives: {crime_total_positives}\")\n",
    "print(f\"Crime total (true) positive rate: {crime_total_pr:.2f}\")\n",
    "\n",
    "print(f\"X_train_crime.shape: {X_train_crime.shape}\")\n",
    "print(f\"X_val_crime.shape: {X_val_crime.shape}\")\n",
    "print(f\"X_test_crime.shape: {X_test_crime.shape}\")\n",
    "print(f\"y_train_crime.shape: {y_train_crime.shape}\")\n",
    "print(f\"y_val_crime.shape: {y_val_crime.shape}\")\n",
    "print(f\"y_test_crime.shape: {y_test_crime.shape}\")\n",
    "\n",
    "display(X_train_crime.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step trains XGBoost on the crime dataset and saves the pretrained model, its predictions and probabilities.\n",
    "y_train_pred, y_test_pred, y_val_pred = crime_xgb_train_predict(\n",
    "    X_train=X_train_crime,\n",
    "    X_val=X_val_crime,\n",
    "    X_test=X_test_crime,\n",
    "    y_train=y_train_crime,\n",
    "    crime_train_predictions_filename=crime_xgb_train_predictions_filename,\n",
    "    crime_val_predictions_filename=crime_xgb_val_predictions_filename,\n",
    "    crime_test_predictions_filename=crime_xgb_test_predictions_filename,\n",
    "    clf_filename=clf_xgb_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate in training predictions: 0.11\n",
      "Positive rate in validation predictions: 0.11\n",
      "Positive rate in test predictions: 0.11\n",
      "Crime true positive rate in training set: 0.24\n",
      "Crime true positive rate in validation set: 0.22\n",
      "Crime true positive rate in test set: 0.22\n",
      "Crime validation accuracy: 0.73\n",
      "Crime test accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "crime_y_train_pr = y_train_pred.sum() / y_train_pred.shape[0]\n",
    "crime_y_val_pr = y_val_pred.sum() / y_val_pred.shape[0]\n",
    "crime_y_test_pr = y_test_pred.sum() / y_test_pred.shape[0]\n",
    "print(f\"Positive rate in training predictions: {crime_y_train_pr:.2f}\")\n",
    "print(f\"Positive rate in validation predictions: {crime_y_val_pr:.2f}\")\n",
    "print(f\"Positive rate in test predictions: {crime_y_test_pr:.2f}\")\n",
    "\n",
    "crime_y_train_tpr = (y_train_pred & y_train_crime).sum() / y_train_crime.sum()\n",
    "crime_y_val_tpr = (y_val_pred & y_val_crime).sum() / y_val_crime.sum()\n",
    "crime_y_test_tpr = (y_test_pred & y_test_crime).sum() / y_test_crime.sum()\n",
    "print(f\"Crime true positive rate in training set: {crime_y_train_tpr:.2f}\")\n",
    "print(f\"Crime true positive rate in validation set: {crime_y_val_tpr:.2f}\")\n",
    "print(f\"Crime true positive rate in test set: {crime_y_test_tpr:.2f}\")\n",
    "\n",
    "crime_val_acc = (y_val_pred == y_val_crime).sum() / y_val_crime.shape[0]\n",
    "crime_test_acc = (y_test_pred == y_test_crime).sum() / y_test_crime.shape[0]\n",
    "print(f\"Crime validation accuracy: {crime_val_acc:.2f}\")\n",
    "print(f\"Crime test accuracy: {crime_test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Audit Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Overlapping Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the data into spatial clusters using the KMeans clustering method for the initial center and with increasing radii starting from each center generates overlapping clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total seeds: 10\n",
      "Total radii: 4\n",
      "Total regions created: 40\n",
      "There are 1987 points that are not covered by the regions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Search for closest regions to assign uncovered points: 100%|██████████| 1987/1987 [01:39<00:00, 19.89it/s]\n",
      "Adding uncovered points to regions: 1987it [00:55, 35.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 points that are not covered by the regions\n",
      "There are 0 points that are not covered by the regions\n",
      "There are 0 points that are not covered by the regions of train set\n",
      "There are 0 points that are not covered by the regions of val set\n",
      "There are 0 points that are not covered by the regions of test set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'overlap_k_10_radii_4_crime'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divides the crime data into spatial clusters \n",
    "\n",
    "overlapping = True\n",
    "k = 10\n",
    "radii = np.arange(0.01, 0.1, 0.03)\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=crime_xgb_train_predictions_filename,\n",
    "    val_with_loc_filename=crime_xgb_val_predictions_filename,\n",
    "    test_with_loc_filename=crime_xgb_test_predictions_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=crime_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    "    with_partitioning_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total seeds: 100\n",
      "Total radii: 30\n",
      "Total regions created: 3000\n",
      "There are 2149 points that are not covered by the regions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Search for closest regions to assign uncovered points: 100%|██████████| 2149/2149 [01:58<00:00, 18.15it/s]\n",
      "Adding uncovered points to regions: 2149it [01:08, 31.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 points that are not covered by the regions\n",
      "There are 0 points that are not covered by the regions\n",
      "There are 0 points that are not covered by the regions of train set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'overlap_k_100_radii_30_lar'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divides the lar data into spatial clusters \n",
    "\n",
    "overlapping = True\n",
    "k = 100\n",
    "radii = np.arange(0.05, 1.51, 0.05)\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=lar_labels_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=lar_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Non-Overlapping Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* overlapping=False to ensure that each data point belongs to only one region.\n",
    "* Keep k=10 clusters.\n",
    "* radii=None since overlapping is disabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total regions created: 8\n",
      "There are 0 points that are not covered by the regions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Search for closest regions to assign uncovered points: 0it [00:00, ?it/s]\n",
      "Adding uncovered points to regions: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 points that are not covered by the regions\n",
      "There are 0 points that are not covered by the regions\n",
      "There are 0 points that are not covered by the regions of train set\n",
      "There are 0 points that are not covered by the regions of val set\n",
      "There are 0 points that are not covered by the regions of test set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'non_overlap_k_8_crime'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divides the crime data into spatial non-overlapping clusters using the KMeans clustering method.\n",
    "overlapping = False\n",
    "k = 8\n",
    "radii = None\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=crime_xgb_train_predictions_filename,\n",
    "    val_with_loc_filename=crime_xgb_val_predictions_filename,\n",
    "    test_with_loc_filename=crime_xgb_test_predictions_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=crime_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    "    with_partitioning_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total regions created: 100\n",
      "There are 0 points that are not covered by the regions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Search for closest regions to assign uncovered points: 0it [00:00, ?it/s]\n",
      "Adding uncovered points to regions: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 points that are not covered by the regions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 points that are not covered by the regions\n",
      "There are 0 points that are not covered by the regions of train set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'non_overlap_k_100_lar'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divides the lar data into spatial non-overlapping clusters using the KMeans clustering method.\n",
    "\n",
    "overlapping = False\n",
    "k = 100\n",
    "radii = None\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=lar_labels_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=lar_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid with max rowsXcolumns = 5X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Boundary:  33.3427 34.7907 -118.7668 -117.7157\n",
      "Val Boundary:  33.7058 34.5477 -118.6673 -117.7115\n",
      "Test Boundary:  33.7062 34.634 -118.7668 -117.7528\n",
      "Global Boundary:  33.3427 34.7907 -118.7668 -117.7115\n"
     ]
    }
   ],
   "source": [
    "# Create partitionings with max 5X5 row and columns for CRIME\n",
    "create_grid_partitioning(\n",
    "    5,\n",
    "    5,\n",
    "    train_with_loc_filename=crime_xgb_train_predictions_filename,\n",
    "    val_with_loc_filename=crime_xgb_val_predictions_filename,\n",
    "    test_with_loc_filename=crime_xgb_test_predictions_filename,\n",
    "    partitioning_dir=partioning_base_path,\n",
    "    dataset_name=crime_dataset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Boundary:  19.5361762 64.8944045 -161.8508035 -67.1081422\n",
      "Global Boundary:  19.5361762 64.8944045 -161.8508035 -67.1081422\n"
     ]
    }
   ],
   "source": [
    "# Create partitionings with max 5X5 row and columns for LAR\n",
    "create_grid_partitioning(\n",
    "    5,\n",
    "    5,\n",
    "    train_with_loc_filename=lar_labels_filename,\n",
    "    partitioning_dir=partioning_base_path,\n",
    "    dataset_name=lar_dataset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Crime Semi-Synthetic Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unfair By Design World Using Non-Overlapping Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats with generation of true types with binomial of rho 0.8 making the world unfair:\n",
      "N=142641 points\n",
      "P=114112 positives\n",
      "Original MLR: 0.433\n",
      "Significance threshold: 6.164\n",
      "Total significant regions: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "actual flips: 29610\n",
      "pos2neg flips: 14805, neg2pos flips 14805, total: 29610\n",
      "Unfair World MLR: 3854.783\n",
      "Significance threshold: 8.920\n",
      "Total significant regions: 8\n"
     ]
    }
   ],
   "source": [
    "clf_name, partioning_type_name, overlap =  \"xgb\", \"non_overlap_k_8\", False\n",
    "res_desc_label, partioning_name, prediction_name = (\n",
    "    combine_world_info(crime_dataset_name, partioning_type_name, clf_name)\n",
    ")\n",
    "_, _, test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, crime_dataset_name\n",
    ")\n",
    "\n",
    "create_unfair_world(\n",
    "    rho=0.8,\n",
    "    test_path_info=test_path_info,\n",
    "    predictions_path=predictions_base_path,\n",
    "    partioning_name=partioning_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unfair By Design World Using Overlapping Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats with generation of true types with binomial of rho 0.8 making the world unfair:\n",
      "N=142641 points\n",
      "P=114112 positives\n",
      "Original MLR: 0.541\n",
      "Significance threshold: 8.147\n",
      "Total significant regions: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "actual flips: 41422\n",
      "pos2neg flips: 20711, neg2pos flips 20711, total: 41422\n",
      "Unfair World MLR: 7325.512\n",
      "Significance threshold: 6.898\n",
      "Total significant regions: 40\n"
     ]
    }
   ],
   "source": [
    "clf_name, partioning_type_name, overlap =  \"xgb\", \"overlap_k_10_radii_4\", True\n",
    "res_desc_label, partioning_name, prediction_name = (\n",
    "    combine_world_info(crime_dataset_name, partioning_type_name, clf_name)\n",
    ")\n",
    "_, _, test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, crime_dataset_name\n",
    ")\n",
    "\n",
    "create_unfair_world(\n",
    "    rho=0.8,\n",
    "    test_path_info=test_path_info,\n",
    "    predictions_path=predictions_base_path,\n",
    "    partioning_name=partioning_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unfair By Design World Using Grid with max rowsXcolumns = 5X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats with generation of true types with binomial of rho 0.8 making the world unfair:\n",
      "N=142641 points\n",
      "P=114112 positives\n",
      "Original MLR: 0.261\n",
      "Significance threshold: 8.706\n",
      "Total significant regions: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "actual flips: 45284\n",
      "pos2neg flips: 22642, neg2pos flips 22642, total: 45284\n",
      "Unfair World MLR: 2224.842\n",
      "Significance threshold: 5.978\n",
      "Total significant regions: 103\n"
     ]
    }
   ],
   "source": [
    "clf_name, partioning_type_name, overlap =  \"xgb\", \"5_x_5\", True\n",
    "res_desc_label, partioning_name, prediction_name = (\n",
    "    combine_world_info(crime_dataset_name, partioning_type_name, clf_name)\n",
    ")\n",
    "_, _,  test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, crime_dataset_name\n",
    ")\n",
    "\n",
    "create_unfair_world(\n",
    "    rho=0.8,\n",
    "    test_path_info=test_path_info,\n",
    "    predictions_path=predictions_base_path,\n",
    "    partioning_name=partioning_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promis_env",
   "language": "python",
   "name": "promis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

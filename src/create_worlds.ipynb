{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed for preprocessing the CRIME, LAR datasets, training XGB on CRIME, generating predictions, and creating spatial partitionings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paths to the neccessary read/write folders are set to the below values:\n",
    "\n",
    "**Paths**\n",
    "* base_path: The main directory where all dataset-related files are stored. The default value is *../data/*\n",
    "* datasets_base_path: Path where the raw datasets are stored. The default value is *base_path/datasets/*\n",
    "* predictions_base_path: Path where base model predictions are saved. The default value is *base_path/predictions/*\n",
    "* preprocess_path: Path where true labels are stored. The default value is *base_path/preprocess/*\n",
    "* clf_base_path: Path where trained machine learning models are saved. The default value is *base_path/clf/*\n",
    "* partioning_base_path: Path where partitioning results are saved. The default value is *base_path/partitionings/*\n",
    "* crime_data_filename: The path to the crime dataset. The default value is *base_path/datasets/Crime_Data_from_2010_to_2019.csv.*\n",
    "* lar_data_filename: The path to the crime dataset. The default value is *base_path/datasets/B4TYDEB6GKMZO031MB27_header.csv.*\n",
    "* census_gazetteer_data_filename: The path to the crime dataset. The default value is *base_path/datasets/2021_Gaz_tracts_national.txt.*\n",
    "\n",
    "**Produced Filenames Interpretation**\n",
    "* partitionings: \\<set name>\\_regions_\\<partitioning name>_\\<dataset name>.csv.\n",
    "* partitionings_ids: \\<set name>\\_regions_\\<partitioning name>_\\<dataset name>_ids.csv: same audit regions with partitionings in format where each id refers to a partitioning.\n",
    "* predictions: \\<set_name>_pred_<clf_name>_\\<dataset>\n",
    "where:\n",
    "\n",
    "* \\<set name>: train/val/set\n",
    "* \\<partitioning name>: \n",
    "    * 5_x_5 (ovelapping partitionings with max 5 row and max 5 columns i.e. 24 partitionings in toal excluding the 1x1), \n",
    "    * non_overlap_k_\\<n\\_regions> (non-overlapping regions produced by KMeans with <n\\_regions> centers), \n",
    "    * overlap_k_\\<n\\_regions>\\_radii_\\<n_radii> (overlapping regions starting from <n\\_regions> centers defined by KMeans and defing regions with max radius-boarders defined by the <n_radii> total radii).\n",
    "* \\<dataset name>: crime/lar\n",
    "* \\<clf_name>: xgb/dnn/semi\\_synthetic\\_regions_\\<partitioning_name> (the dnn is trained and saved in the src/experiments/dnn_exp.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.xgb_crime import crime_xgb_train_predict\n",
    "from utils.preprocess import proprocess_crime, preprocess_lar\n",
    "from utils.create_partitioning import create_kmeans_partioning, create_grid_partitioning\n",
    "from utils.create_unfair_world import create_unfair_world\n",
    "from utils.results_names_utils import combine_world_info, get_train_val_test_paths\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../data/\"\n",
    "datasets_base_path = f\"{base_path}datasets/\"\n",
    "preprocess_base_path = f\"{base_path}preprocess/\"\n",
    "predictions_base_path = f\"{base_path}predictions/\"\n",
    "clf_base_path = f\"{base_path}clf/\"\n",
    "partioning_base_path = f\"{base_path}partitionings/\"\n",
    "crime_data_filename = f\"{datasets_base_path}Crime_Data_from_2010_to_2019.csv\"\n",
    "lar_data_filename = f\"{datasets_base_path}B4TYDEB6GKMZO031MB27_header.csv\"\n",
    "census_gazetteer_data_filename = f\"{datasets_base_path}2021_Gaz_tracts_national.txt\"\n",
    "datasets_zip_fname = f\"{datasets_base_path}datasets.zip\"\n",
    "datasets_extract_path = f\"{datasets_base_path}\"\n",
    "\n",
    "for dir in [datasets_base_path, predictions_base_path, clf_base_path, partioning_base_path, preprocess_base_path]:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip datasets files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(datasets_zip_fname):\n",
    "    with zipfile.ZipFile(datasets_zip_fname, 'r') as zip_ref:\n",
    "        zip_ref.extractall(datasets_extract_path)\n",
    "    print(\"All files extracted successfully.\")\n",
    "else:\n",
    "    print(f\"File {datasets_zip_fname} does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set - Combine the neccessary paths, labels descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_dataset_name = \"crime\"\n",
    "lar_dataset_name = \"lar\"\n",
    "\n",
    "crime_xgb_clf_name = \"xgb_crime\"\n",
    "crime_xgb_predictions_name = f\"pred_{crime_xgb_clf_name}\"\n",
    "crime_xgb_train_predictions_filename = f\"{predictions_base_path}train_{crime_xgb_predictions_name}.csv\"\n",
    "crime_xgb_val_predictions_filename = f\"{predictions_base_path}val_{crime_xgb_predictions_name}.csv\"\n",
    "crime_xgb_test_predictions_filename = f\"{predictions_base_path}test_{crime_xgb_predictions_name}.csv\"\n",
    "clf_xgb_filename = f\"{clf_base_path}{crime_xgb_clf_name}.joblib\"\n",
    "\n",
    "lar_labels_filename = f\"{preprocess_base_path}lar.csv\"\n",
    "\n",
    "crime_dnn_clf_name = \"dnn_crime\"\n",
    "crime_dnn_predictions_name = f\"pred_{crime_dnn_clf_name}\"\n",
    "crime_dnn_train_predictions_filename = f\"{predictions_base_path}train_{crime_dnn_predictions_name}.csv\"\n",
    "crime_dnn_val_predictions_filename = f\"{predictions_base_path}val_{crime_dnn_predictions_name}.csv\"\n",
    "crime_dnn_test_predictions_filename = f\"{predictions_base_path}test_{crime_dnn_predictions_name}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lar_df = preprocess_lar(lar_data_filename, census_gazetteer_data_filename, preprocess_base_path)\n",
    "print(f\"LAR total rows: {lar_df.shape[0]}\")\n",
    "print(f\"LAR total positive rows: {lar_df['label'].sum()}\")\n",
    "lar_pr = lar_df['label'].sum() / lar_df.shape[0]\n",
    "print(f\"LAR positive rate: {lar_pr:.2f}\")\n",
    "display(lar_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_crime, X_val_crime, X_test_crime, y_train_crime, y_val_crime, y_test_crime = proprocess_crime(crime_data_filename, preprocess_base_path)\n",
    "\n",
    "crime_total_positives =  y_train_crime.sum() + y_val_crime.sum() + y_test_crime.sum() \n",
    "crime_total_rows = y_train_crime.shape[0] + y_val_crime.shape[0] + y_test_crime.shape[0]\n",
    "crime_total_pr = crime_total_positives / crime_total_rows\n",
    "\n",
    "print(f\"Crime total rows: {crime_total_rows}\")\n",
    "print(f\"Crime total positives: {crime_total_positives}\")\n",
    "print(f\"Crime total (true) positive rate: {crime_total_pr:.2f}\")\n",
    "\n",
    "print(f\"X_train_crime.shape: {X_train_crime.shape}\")\n",
    "print(f\"X_val_crime.shape: {X_val_crime.shape}\")\n",
    "print(f\"X_test_crime.shape: {X_test_crime.shape}\")\n",
    "print(f\"y_train_crime.shape: {y_train_crime.shape}\")\n",
    "print(f\"y_val_crime.shape: {y_val_crime.shape}\")\n",
    "print(f\"y_test_crime.shape: {y_test_crime.shape}\")\n",
    "\n",
    "display(X_train_crime.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step trains XGBoost on the crime dataset and saves the pretrained model, its predictions and probabilities.\n",
    "y_train_pred, y_test_pred, y_val_pred = crime_xgb_train_predict(\n",
    "    X_train=X_train_crime,\n",
    "    X_val=X_val_crime,\n",
    "    X_test=X_test_crime,\n",
    "    y_train=y_train_crime,\n",
    "    crime_train_predictions_filename=crime_xgb_train_predictions_filename,\n",
    "    crime_val_predictions_filename=crime_xgb_val_predictions_filename,\n",
    "    crime_test_predictions_filename=crime_xgb_test_predictions_filename,\n",
    "    clf_filename=clf_xgb_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_y_train_pr = y_train_pred.sum() / y_train_pred.shape[0]\n",
    "crime_y_val_pr = y_val_pred.sum() / y_val_pred.shape[0]\n",
    "crime_y_test_pr = y_test_pred.sum() / y_test_pred.shape[0]\n",
    "print(f\"Positive rate in training predictions: {crime_y_train_pr:.2f}\")\n",
    "print(f\"Positive rate in validation predictions: {crime_y_val_pr:.2f}\")\n",
    "print(f\"Positive rate in test predictions: {crime_y_test_pr:.2f}\")\n",
    "\n",
    "crime_y_train_tpr = (y_train_pred & y_train_crime).sum() / y_train_crime.sum()\n",
    "crime_y_val_tpr = (y_val_pred & y_val_crime).sum() / y_val_crime.sum()\n",
    "crime_y_test_tpr = (y_test_pred & y_test_crime).sum() / y_test_crime.sum()\n",
    "print(f\"Crime true positive rate in training set: {crime_y_train_tpr:.2f}\")\n",
    "print(f\"Crime true positive rate in validation set: {crime_y_val_tpr:.2f}\")\n",
    "print(f\"Crime true positive rate in test set: {crime_y_test_tpr:.2f}\")\n",
    "\n",
    "crime_val_acc = (y_val_pred == y_val_crime).sum() / y_val_crime.shape[0]\n",
    "crime_test_acc = (y_test_pred == y_test_crime).sum() / y_test_crime.shape[0]\n",
    "print(f\"Crime validation accuracy: {crime_val_acc:.2f}\")\n",
    "print(f\"Crime test accuracy: {crime_test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step trains a DNN on the crime dataset and saves the predictions and probabilities.\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersect = tf.reduce_sum(y_pred * y_true, axis=0) + K.epsilon()\n",
    "    denominator = tf.reduce_sum(y_pred, axis=0) + tf.reduce_sum(y_true, axis=0)\n",
    "    dice_scores = 2 * intersect / (denominator + tf.keras.backend.epsilon())\n",
    "    return 1 - dice_scores\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    loss = dice(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "BATCH_SIZE = 64*64\n",
    "LEARNING_RATE = 0.0001\n",
    "LEARNING_RATE_INIT = LEARNING_RATE\n",
    "EPOCH_TRAIN = 100\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "initializer = tf.keras.initializers.TruncatedNormal(stddev=0.5, seed=SEED)\n",
    "base_model = Sequential([\n",
    "    Dense(100, activation='elu', input_dim=X_train_crime.shape[1], kernel_initializer=initializer),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='elu', kernel_initializer=initializer),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(2, activation='softmax', kernel_initializer=initializer),\n",
    "])\n",
    "\n",
    "print(base_model.summary())\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "base_model.compile(optimizer=optimizer, loss=custom_loss, metrics=['accuracy'])\n",
    "\n",
    "# Start Training\n",
    "history = base_model.fit(\n",
    "    X_train_crime,\n",
    "    y_train_crime,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCH_TRAIN,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_val_crime, y_val_crime),\n",
    ")\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Predict the label\n",
    "y_train_pred_base = base_model.predict(X_train_crime, batch_size=BATCH_SIZE)\n",
    "y_val_pred_base =  base_model.predict(X_val_crime, batch_size=BATCH_SIZE)\n",
    "y_test_pred_base =  base_model.predict(X_test_crime, batch_size=BATCH_SIZE)\n",
    "\n",
    "#Change Softmax to class\n",
    "class_y_train_pred_base = np.argmax(y_train_pred_base, axis=-1)\n",
    "class_y_val_pred_base = np.argmax(y_val_pred_base, axis=-1)\n",
    "class_y_test_pred_base = np.argmax(y_test_pred_base, axis=-1)\n",
    "\n",
    "base_test_f1 = f1_score(y_test_crime,class_y_test_pred_base)\n",
    "\n",
    "print(f\"F1 train: {f1_score(y_train_crime,class_y_train_pred_base)}, F1 val: {f1_score(y_val_crime,class_y_val_pred_base)}, F1 test: , {f1_score(y_test_crime,class_y_test_pred_base)}\")\n",
    "\n",
    "pos_class_prob_idx = 1  # Positive class index\n",
    "\n",
    "y_train_base_pred_proba = base_model.predict(X_train_crime, batch_size=BATCH_SIZE)[:, pos_class_prob_idx]\n",
    "y_val_base_pred_proba = base_model.predict(X_val_crime, batch_size=BATCH_SIZE)[:, pos_class_prob_idx]\n",
    "y_test_base_pred_proba = base_model.predict(X_test_crime, batch_size=BATCH_SIZE)[:, pos_class_prob_idx]\n",
    "\n",
    "preds_df = pd.DataFrame({\n",
    "    \"pred\": class_y_train_pred_base,\n",
    "    \"pred_proba\": y_train_base_pred_proba,\n",
    "})\n",
    "\n",
    "val_preds_df = pd.DataFrame({\n",
    "    \"pred\": class_y_val_pred_base,\n",
    "    \"prob\": y_val_base_pred_proba\n",
    "})\n",
    "\n",
    "test_preds_df = pd.DataFrame({\n",
    "    \"pred\": class_y_test_pred_base,\n",
    "    \"prob\": y_test_base_pred_proba\n",
    "})\n",
    "\n",
    "preds_df.to_csv(crime_dnn_train_predictions_filename, index=False)\n",
    "val_preds_df.to_csv(crime_dnn_val_predictions_filename, index=False)\n",
    "test_preds_df.to_csv(crime_dnn_test_predictions_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Audit Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Overlapping Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the data into spatial clusters using the KMeans clustering method for the initial center and with increasing radii starting from each center generates overlapping clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides the crime data into spatial clusters \n",
    "\n",
    "overlapping = True\n",
    "k = 10\n",
    "radii = np.arange(0.01, 0.1, 0.03)\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=crime_xgb_train_predictions_filename,\n",
    "    val_with_loc_filename=crime_xgb_val_predictions_filename,\n",
    "    test_with_loc_filename=crime_xgb_test_predictions_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=crime_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    "    with_partitioning_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides the lar data into spatial clusters \n",
    "\n",
    "overlapping = True\n",
    "k = 100\n",
    "radii = np.arange(0.05, 1.51, 0.05)\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=lar_labels_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=lar_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Non-Overlapping Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* overlapping=False to ensure that each data point belongs to only one region.\n",
    "* Keep k=10 clusters.\n",
    "* radii=None since overlapping is disabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides the crime data into spatial non-overlapping clusters using the KMeans clustering method.\n",
    "overlapping = False\n",
    "k = 8\n",
    "radii = None\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=crime_xgb_train_predictions_filename,\n",
    "    val_with_loc_filename=crime_xgb_val_predictions_filename,\n",
    "    test_with_loc_filename=crime_xgb_test_predictions_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=crime_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    "    with_partitioning_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides the lar data into spatial non-overlapping clusters using the KMeans clustering method.\n",
    "\n",
    "overlapping = False\n",
    "k = 100\n",
    "radii = None\n",
    "create_kmeans_partioning(\n",
    "    train_with_loc_filename=lar_labels_filename,\n",
    "    partioning_base_path=partioning_base_path,\n",
    "    dataset_name=lar_dataset_name,\n",
    "    overlapping=overlapping,\n",
    "    k=k,\n",
    "    radii=radii,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid with max rowsXcolumns = 5X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create partitionings with max 5X5 row and columns for CRIME\n",
    "create_grid_partitioning(\n",
    "    5,\n",
    "    5,\n",
    "    train_with_loc_filename=crime_xgb_train_predictions_filename,\n",
    "    val_with_loc_filename=crime_xgb_val_predictions_filename,\n",
    "    test_with_loc_filename=crime_xgb_test_predictions_filename,\n",
    "    partitioning_dir=partioning_base_path,\n",
    "    dataset_name=crime_dataset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create partitionings with max 5X5 row and columns for LAR\n",
    "create_grid_partitioning(\n",
    "    5,\n",
    "    5,\n",
    "    train_with_loc_filename=lar_labels_filename,\n",
    "    partitioning_dir=partioning_base_path,\n",
    "    dataset_name=lar_dataset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Crime Semi-Synthetic Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unfair By Design World Using Non-Overlapping Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name, partioning_type_name, overlap =  \"xgb\", \"non_overlap_k_8\", False\n",
    "res_desc_label, partioning_name, prediction_name = (\n",
    "    combine_world_info(crime_dataset_name, partioning_type_name, clf_name)\n",
    ")\n",
    "_, _, test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, crime_dataset_name\n",
    ")\n",
    "\n",
    "create_unfair_world(\n",
    "    rho=0.8,\n",
    "    test_path_info=test_path_info,\n",
    "    predictions_path=predictions_base_path,\n",
    "    partioning_name=partioning_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unfair By Design World Using Overlapping Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name, partioning_type_name, overlap =  \"xgb\", \"overlap_k_10_radii_4\", True\n",
    "res_desc_label, partioning_name, prediction_name = (\n",
    "    combine_world_info(crime_dataset_name, partioning_type_name, clf_name)\n",
    ")\n",
    "_, _, test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, crime_dataset_name\n",
    ")\n",
    "\n",
    "create_unfair_world(\n",
    "    rho=0.8,\n",
    "    test_path_info=test_path_info,\n",
    "    predictions_path=predictions_base_path,\n",
    "    partioning_name=partioning_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unfair By Design World Using Grid with max rowsXcolumns = 5X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name, partioning_type_name, overlap =  \"xgb\", \"5_x_5\", True\n",
    "res_desc_label, partioning_name, prediction_name = (\n",
    "    combine_world_info(crime_dataset_name, partioning_type_name, clf_name)\n",
    ")\n",
    "_, _,  test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, crime_dataset_name\n",
    ")\n",
    "\n",
    "create_unfair_world(\n",
    "    rho=0.8,\n",
    "    test_path_info=test_path_info,\n",
    "    predictions_path=predictions_base_path,\n",
    "    partioning_name=partioning_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PROMIS Env",
   "language": "python",
   "name": "promis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

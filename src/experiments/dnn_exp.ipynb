{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the experiment, where a DNN is the base model to mitigate. We consider two fairness definitions: statistical parity and equal opportunity. All three compared methods are assessed on statistical parity, while only FairWhere and PROMIS are assessed on equal opportunity. For FairWhere we define the distance for each partition as the absoluted difference of the partition recall and the overall model recall and for statistical parity we use the positive ratio as metric\n",
    "The three types of audit regions are tested and with the 2 fairness notions result in 6 experiments.\n",
    "\n",
    "Initially the base DNN is trained. FairWhere continues training on the training set with the goal of mitigating spatial bias. At the start of fairness training, each sampled partitioning is used for 5 epochs before transitioning to the next, iterating over 120 different samples (equivalent to five full enumerations over all 24 partitioning candidates). Subsequently, each epoch samples a new partitioning, continuing for 720 samples (equivalent to thirty full enumerations). In total, each partitioning is expected to be used for 50 epochs throughout\n",
    "the training process.\n",
    "\n",
    "The predictions of the base and corrected (by FairWhere) model are saved for later analysis.\n",
    "\n",
    "The maximum budget, given as input for PROMIS and SpatialFlips is computed by the absolute difference of the predictions on the validation set between the base DNN and FairWhere models. \n",
    "\n",
    "PROMIS methods apply the thresholds adjustment approach using the validation set, while SpatialFlips apply flips directly on the test set.\n",
    "\n",
    "The \"pretrained\" PROMIS, SpatialFlip models are saved for later analysis on the test set.\n",
    "\n",
    "You may opt which experiment to run by uncommenting the relate part in the section choose experiment to run. To rerun an experiment restart the notebook (for reprodicaability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2287,
     "status": "ok",
     "timestamp": 1702284248589,
     "user": {
      "displayName": "ZHOU TIANHENG",
      "userId": "06545871880155544798"
     },
     "user_tz": -60
    },
    "id": "nfrZK-fWMprk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score,recall_score, precision_score,f1_score, balanced_accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from methods.models.optimization_model import SpatialOptimFairnessModel \n",
    "from methods.models.spatial_flip_model import SpatialFlipFairnessModel\n",
    "from utils.results_names_utils import combine_world_info\n",
    "from utils.data_utils import get_y, read_scanned_regs, get_pos_info_regions\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Experiment to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Opportunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fair_notion = \"equal_opportunity\" \n",
    "# partioning_type_name = \"5_x_5\"\n",
    "# n_flips_start = 400\n",
    "# overlap=True\n",
    "\n",
    "# fair_notion = \"equal_opportunity\" \n",
    "# partioning_type_name = \"non_overlap_k_8\"\n",
    "# n_flips_start = 400\n",
    "# overlap=False\n",
    "\n",
    "# fair_notion = \"equal_opportunity\" \n",
    "# partioning_type_name = \"overlap_k_10_radii_4\"\n",
    "# n_flips_start = 1000\n",
    "# overlap=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fair_notion = \"statistical_parity\" \n",
    "# partioning_type_name = \"5_x_5\"\n",
    "# n_flips_start = 1200\n",
    "# overlap=True\n",
    "\n",
    "# fair_notion = \"statistical_parity\" \n",
    "# partioning_type_name = \"non_overlap_k_8\"\n",
    "# n_flips_start = 900\n",
    "# overlap=False\n",
    "\n",
    "# fair_notion = \"statistical_parity\" \n",
    "# partioning_type_name = \"overlap_k_10_radii_4\"\n",
    "# n_flips_start = 3000\n",
    "# overlap=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/\"\n",
    "prediction_dir = f'{data_path}predictions/' # folder in data path to save the base model predictions\n",
    "partitioning_dir = f'{data_path}partitionings/' # folder in data path to save the partitionings\n",
    "preprocess_dir = f'{data_path}preprocess/'\n",
    "dataset_name = \"crime\"\n",
    "clf_name = \"dnn\"\n",
    "results_path = \"../../results/dnn_exp/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_desc_label, partioning_name, prediction_name = combine_world_info(\n",
    "    dataset_name, partioning_type_name, clf_name\n",
    ")\n",
    "results_path = f\"{results_path}{res_desc_label}/\"\n",
    "keras_models_dir = f'{results_path}keras_models/{fair_notion}/' # folder to save base and where model\n",
    "sp_flip_models_dir = f'{results_path}spatial_flip_models/{fair_notion}/'\n",
    "sp_opt_models_dir = f'{results_path}spatial_optim_models/{fair_notion}/'\n",
    "base_model_fname = f\"{data_path}clf/dnn_{dataset_name}.keras\"\n",
    "for dir in [results_path, keras_models_dir]:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE_LABEL: pr\n"
     ]
    }
   ],
   "source": [
    "SCORE_LABEL = 'recall' if fair_notion == 'equal_opportunity' else 'pr'\n",
    "print(f\"SCORE_LABEL: {SCORE_LABEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64*64\n",
    "LEARNING_RATE = 0.0001\n",
    "LEARNING_RATE_INIT = LEARNING_RATE\n",
    "EPOCH_TRAIN = 100\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get F1 list of all partitions\n",
    "def get_weighted_f1_one(model, X_Test, y_Test, all_partitioning_data_list, index1, index2):\n",
    "    w_f1_list = np.zeros((index1 * index2), dtype='float')\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_Test, batch_size=BATCH_SIZE),axis = -1)\n",
    "\n",
    "    data_list = all_partitioning_data_list[(index1, index2)]\n",
    "\n",
    "    for i in range(index1 * index2):\n",
    "        if data_list[i].size == 0:\n",
    "            continue\n",
    "        y_pred_partition = y_pred[data_list[i]]\n",
    "        y_test_partition = y_Test[data_list[i]]\n",
    "\n",
    "        f1_value = f1_score(y_test_partition,y_pred_partition,zero_division = 0)\n",
    "        w_f1_list[i] = f1_value\n",
    "\n",
    "    return w_f1_list\n",
    "\n",
    "#Get recall list of all partitions\n",
    "def get_weighted_recall(model, X_Test, y_Test, all_partitioning_data_list, index1, index2):\n",
    "    w_tpr_list = np.zeros((index1 * index2), dtype='float')\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_Test, batch_size=BATCH_SIZE),axis = -1)\n",
    "\n",
    "    data_list = all_partitioning_data_list[(index1, index2)]\n",
    "\n",
    "    for i in range(index1 * index2):\n",
    "        if data_list[i].size == 0:\n",
    "            continue\n",
    "        y_pred_partition = y_pred[data_list[i]]\n",
    "        y_test_partition = y_Test.iloc[data_list[i]]\n",
    "\n",
    "        rec = recall_score(y_test_partition,y_pred_partition,zero_division = 0)\n",
    "        w_tpr_list[i] = rec\n",
    "\n",
    "    return w_tpr_list\n",
    "\n",
    "def get_pr(y_true, y_pred):\n",
    "    return np.sum(y_pred) / len(y_pred)\n",
    "\n",
    "\n",
    "def get_weighted_pr(\n",
    "    model, X_Test, y_Test, all_partitioning_data_list, index1, index2\n",
    "):\n",
    "    w_pr_list = np.zeros((index1 * index2), dtype=\"float\")\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_Test, batch_size=BATCH_SIZE), axis=-1)\n",
    "\n",
    "    data_list = all_partitioning_data_list[(index1, index2)]\n",
    "\n",
    "    for i in range(index1 * index2):\n",
    "        if data_list[i].size == 0:\n",
    "            continue\n",
    "        y_pred_partition = y_pred[data_list[i]]\n",
    "\n",
    "        pr = get_pr(None, y_pred_partition)\n",
    "        w_pr_list[i] = pr\n",
    "\n",
    "    return w_pr_list\n",
    "\n",
    "score_labels_to_funcs = {\n",
    "    \"pr\": {\n",
    "        \"score_func\": get_pr,\n",
    "        \"weighted_score_func\": get_weighted_pr\n",
    "    },\n",
    "    \"recall\": {\n",
    "        \"score_func\": recall_score,\n",
    "        \"weighted_score_func\": get_weighted_recall\n",
    "    }\n",
    "}\n",
    "score_func = score_labels_to_funcs[SCORE_LABEL][\"score_func\"]\n",
    "weighted_score_func = score_labels_to_funcs[SCORE_LABEL][\"weighted_score_func\"]\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersect = tf.reduce_sum(y_pred * y_true, axis=0) + K.epsilon()\n",
    "    denominator = tf.reduce_sum(y_pred, axis=0) + tf.reduce_sum(y_true, axis=0)\n",
    "    dice_scores = 2 * intersect / (denominator + tf.keras.backend.epsilon())\n",
    "    return 1 - dice_scores\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    loss = dice(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train = pd.read_csv(f\"{preprocess_dir}X_train_crime.csv\")\n",
    "X_val = pd.read_csv(f\"{preprocess_dir}X_val_crime.csv\")\n",
    "X_test = pd.read_csv(f\"{preprocess_dir}X_test_crime.csv\")\n",
    "y_train = pd.read_csv(f\"{preprocess_dir}y_train_crime.csv\")\n",
    "y_val = pd.read_csv(f\"{preprocess_dir}y_val_crime.csv\")\n",
    "y_test = pd.read_csv(f\"{preprocess_dir}y_test_crime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_partitioning_id_df = pd.read_csv(\n",
    "    f\"{partitioning_dir}train_{partioning_name}_partitioning_ids.csv\"\n",
    ")\n",
    "\n",
    "train_partitioning_id_df[\"id\"] = train_partitioning_id_df[\"id\"].apply(\n",
    "    ast.literal_eval\n",
    ")\n",
    "train_partitioning_id_df[\"partitioning\"] = train_partitioning_id_df[\n",
    "    \"partitioning\"\n",
    "].apply(ast.literal_eval)\n",
    "\n",
    "# Get the partitioning data\n",
    "\n",
    "train_ids = train_partitioning_id_df[\"id\"].tolist()\n",
    "X_train_parts = train_partitioning_id_df[\"partitioning\"].tolist()\n",
    "\n",
    "X_train_parts_np = []\n",
    "for i in range(len(X_train_parts)):\n",
    "    cur_partitioning = []\n",
    "    for partition in X_train_parts[i]:\n",
    "        cur_partitioning.append(np.array(partition))\n",
    "    X_train_parts_np.append(cur_partitioning)\n",
    "\n",
    "X_train_id = {id: part for id, part in zip(train_ids, X_train_parts_np)}\n",
    "\n",
    "PARTITIONINGS = train_ids\n",
    "print(\"Partitioning: \", PARTITIONINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oRIUzSsoxy0"
   },
   "source": [
    "##  Train Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.TruncatedNormal(stddev=0.5, seed=SEED)\n",
    "base_model = Sequential([\n",
    "    Dense(100, activation='elu', input_dim=X_train.shape[1], kernel_initializer=initializer),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='elu', kernel_initializer=initializer),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(2, activation='softmax', kernel_initializer=initializer),\n",
    "])\n",
    "\n",
    "print(base_model.summary())\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "global optimizer\n",
    "base_model.compile(optimizer=optimizer, loss=custom_loss, metrics=['accuracy'])\n",
    "\n",
    "# Start Training\n",
    "history = base_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCH_TRAIN,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "# We do not save the model since the same reproducible \n",
    "# trained model has been save in create_worlds.py\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save(base_model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = load_model(\n",
    "    base_model_fname,\n",
    "    custom_objects={\"custom_loss\": custom_loss} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the label\n",
    "y_train_pred_base = base_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "y_val_pred_base =  base_model.predict(X_val, batch_size=BATCH_SIZE)\n",
    "y_test_pred_base =  base_model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "#Change Softmax to class\n",
    "class_y_train_pred_base = np.argmax(y_train_pred_base, axis=-1)\n",
    "class_y_val_pred_base = np.argmax(y_val_pred_base, axis=-1)\n",
    "class_y_test_pred_base = np.argmax(y_test_pred_base, axis=-1)\n",
    "\n",
    "#Prediction Value Count\n",
    "print(np.unique(class_y_train_pred_base,return_counts=True))\n",
    "print(np.unique(class_y_val_pred_base,return_counts=True))\n",
    "print(np.unique(class_y_test_pred_base,return_counts=True))\n",
    "\n",
    "base_test_acc = accuracy_score(y_test,class_y_test_pred_base)\n",
    "base_test_bal_acc = balanced_accuracy_score(y_test,class_y_test_pred_base)\n",
    "base_test_rec = recall_score(y_test,class_y_test_pred_base)\n",
    "base_test_pre = precision_score(y_test,class_y_test_pred_base)\n",
    "base_test_f1 = f1_score(y_test,class_y_test_pred_base)\n",
    "\n",
    "\n",
    "print(f\"Acc train: {accuracy_score(y_train,class_y_train_pred_base)}, Acc val: {accuracy_score(y_val,class_y_val_pred_base)}, Acc test: {accuracy_score(y_test,class_y_test_pred_base)}\")\n",
    "print(f\"Rec train: {recall_score(y_train,class_y_train_pred_base)}, Rec val: {recall_score(y_val,class_y_val_pred_base)} Rec test: {recall_score(y_test,class_y_test_pred_base)}\")\n",
    "print(f\"Pre train: {precision_score(y_train,class_y_train_pred_base)}, Pre val: {precision_score(y_val,class_y_val_pred_base)}, Pre test: {precision_score(y_test,class_y_test_pred_base)}\")\n",
    "print(f\"F1 train: {f1_score(y_train,class_y_train_pred_base)}, F1 val: {f1_score(y_val,class_y_val_pred_base)}, F1 test: , {f1_score(y_test,class_y_test_pred_base)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Base Model Predictions and Generated Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pos_class_prob_idx = 1  # Positive class index\n",
    "\n",
    "#Predict the label\n",
    "y_train_pred_base = base_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "#Change Softmax to class\n",
    "class_y_train_pred_base = np.argmax(y_train_pred_base, axis=-1)\n",
    "GLOBAL_MEAN_base = score_func(y_train, class_y_train_pred_base)\n",
    "\n",
    "y_train_base_pred_proba = base_model.predict(X_train, batch_size=BATCH_SIZE)[:, pos_class_prob_idx]\n",
    "y_val_base_pred_proba = base_model.predict(X_val, batch_size=BATCH_SIZE)[:, pos_class_prob_idx]\n",
    "y_test_base_pred_proba = base_model.predict(X_test, batch_size=BATCH_SIZE)[:, pos_class_prob_idx]\n",
    "\n",
    "preds_df = pd.DataFrame({\n",
    "    \"pred\": class_y_train_pred_base,\n",
    "    \"pred_proba\": y_train_base_pred_proba,\n",
    "})\n",
    "\n",
    "val_preds_df = pd.DataFrame({\n",
    "    \"pred\": class_y_val_pred_base,\n",
    "    \"prob\": y_val_base_pred_proba\n",
    "})\n",
    "\n",
    "test_preds_df = pd.DataFrame({\n",
    "    \"pred\": class_y_test_pred_base,\n",
    "    \"prob\": y_test_base_pred_proba\n",
    "})\n",
    "\n",
    "preds_df.to_csv(f\"{prediction_dir}train_{prediction_name}.csv\", index=False)\n",
    "val_preds_df.to_csv(f\"{prediction_dir}val_{prediction_name}.csv\", index=False)\n",
    "test_preds_df.to_csv(f\"{prediction_dir}test_{prediction_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWf5ZzerpPci"
   },
   "source": [
    "## Motigate Spatial Bias with FairWhere Model\n",
    "Technique used in the Fairness by Where Paper, Bi-Level Framework, train on different random partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data for one way of partitioning\n",
    "def get_partition_data(index1, index2, X_data, y_data, all_partitioning_data_list):\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "\n",
    "    data_list = all_partitioning_data_list[(index1, index2)]\n",
    "    #print(data_list)\n",
    "    for i in range(index1 * index2):\n",
    "        if data_list[i].size == 0:\n",
    "            continue\n",
    "        X_train_list.append(X_data.iloc[data_list[i]])\n",
    "        y_train_list.append(y_data.iloc[data_list[i]])\n",
    "\n",
    "    #print(\"get index {} partition data finished\".format((index1,index2)))\n",
    "\n",
    "    return X_train_list, y_train_list\n",
    "\n",
    "\n",
    "### Self-adpated learning rate, defined in the fairness by where paper\n",
    "def set_lr_weight(index1, index2, w_scores):\n",
    "    global lr_list, GLOBAL_MEAN_base\n",
    "\n",
    "    lr_list = np.zeros((index1 * index2))\n",
    "\n",
    "    #print(\"w_scores: \", w_scores)\n",
    "\n",
    "    lr_list = (GLOBAL_MEAN_base - w_scores)\n",
    "    # percentage\n",
    "    lambda_value = LEARNING_RATE_INIT #0.0005\n",
    "\n",
    "    lr_list = tf.nn.relu(lr_list)\n",
    "    lr_list = lr_list.numpy()\n",
    "\n",
    "    if np.sum(lr_list) > 0:\n",
    "        lr_list = lr_list / np.sum(lr_list) * lambda_value * (index1 * index2)\n",
    "\n",
    "        # maximum to lambda_value\n",
    "        lr_list = lr_list / (np.amax(lr_list) / lambda_value)\n",
    "\n",
    "    # avoid zero\n",
    "    lr_list += K.epsilon()\n",
    "    #print(\"Final lr_list:\", lr_list)\n",
    "    return lr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1702284380228,
     "user": {
      "displayName": "ZHOU TIANHENG",
      "userId": "06545871880155544798"
     },
     "user_tz": -60
    },
    "id": "jnBvWwzjy4ip"
   },
   "outputs": [],
   "source": [
    "#Use intial epoch in case we need to train on different partitions\n",
    "def model_train(model, X_in, y_in, init_epoch_number=0, epoch_train=EPOCH_TRAIN, X_val=None, y_val=None, verbose=0):  #\n",
    "    '''\n",
    "    Input model is complied!\n",
    "    '''\n",
    "\n",
    "    if X_val is None or y_val is None:\n",
    "        return model.fit(\n",
    "            X_in, \n",
    "            y_in, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            initial_epoch=init_epoch_number, \n",
    "            epochs=init_epoch_number + epoch_train, \n",
    "            shuffle=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "    else:\n",
    "        return model.fit(\n",
    "            X_in, \n",
    "            y_in, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            initial_epoch=init_epoch_number, \n",
    "            epochs=init_epoch_number + epoch_train, \n",
    "            shuffle=True,\n",
    "            validation_data=(X_val, y_val), \n",
    "            verbose=verbose,\n",
    "        )\n",
    "    \n",
    "# Bi-level\n",
    "base_model = load_model(\n",
    "    base_model_fname,\n",
    "    custom_objects={\"custom_loss\": custom_loss}\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "loop_list = [4, 30]\n",
    "epoch_list = [5, 1]\n",
    "\n",
    "for i in tqdm(range(len(loop_list)), desc=\"Outer Loop\"):\n",
    "\n",
    "    epochs = epoch_list[i]\n",
    "    loops = loop_list[i]\n",
    "\n",
    "    for l in tqdm(range(loops), desc=\"Training Loops\", leave=False):\n",
    "\n",
    "        random.shuffle(PARTITIONINGS)\n",
    "\n",
    "        for j in tqdm(range(len(PARTITIONINGS)), desc=\"Partitions\", leave=False):\n",
    "            (index1, index2) = PARTITIONINGS[j]\n",
    "\n",
    "            X_train_part, y_train_part = get_partition_data(index1, index2, X_train, y_train, X_train_id)\n",
    "\n",
    "            w_scores = weighted_score_func(base_model, X_train, y_train, X_train_id, index1, index2)\n",
    "            lr_list = set_lr_weight(index1, index2, w_scores,)\n",
    "\n",
    "            for e in tqdm(range(epochs), desc=\"Epochs\", leave=False):\n",
    "\n",
    "                for p in range(len(X_train_part)):\n",
    "\n",
    "                    LEARNING_RATE = lr_list[p]\n",
    "                    for var in optimizer.variables:\n",
    "                        var.assign(tf.zeros_like(var))\n",
    "\n",
    "                    base_model(tf.ones((1, X_train.shape[1])))\n",
    "                    history = model_train(\n",
    "                        base_model, \n",
    "                        X_train_part[p], \n",
    "                        y_train_part[p], \n",
    "                        init_epoch_number=e, \n",
    "                        epoch_train=1, \n",
    "                        X_val=X_val, \n",
    "                        y_val=y_val, \n",
    "                        verbose=0\n",
    "                    )\n",
    "\n",
    "where_fit_time = time.time() - start_time\n",
    "print(f\"Time: {where_fit_time:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Fit Time and Predictions of Mitigated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{results_path}{dataset_name}_{fair_notion}_where_fit_time.txt\", \"w\") as file:\n",
    "    file.write(str(where_fit_time))\n",
    "base_model.save(f\"{keras_models_dir}crime_partition_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_where_model = load_model(f\"{keras_models_dir}crime_partition_model.keras\", custom_objects={\"custom_loss\": custom_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_partition = fair_where_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "y_val_pred_partition = fair_where_model.predict(X_val, batch_size=BATCH_SIZE)\n",
    "y_test_pred_partition = fair_where_model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "class_y_train_pred_partition = np.argmax(y_train_pred_partition, axis=-1)\n",
    "class_y_val_pred_partition = np.argmax(y_val_pred_partition, axis=-1)\n",
    "class_y_test_pred_partition = np.argmax(y_test_pred_partition, axis=-1)\n",
    "\n",
    "\n",
    "pos_class_prob_idx = 1  # Positive class index\n",
    "y_train_partition_pred_proba = fair_where_model.predict(\n",
    "    X_train, batch_size=BATCH_SIZE\n",
    ")[:, pos_class_prob_idx]\n",
    "\n",
    "y_val_partition_pred_proba = fair_where_model.predict(\n",
    "    X_val, batch_size=BATCH_SIZE\n",
    ")[:, pos_class_prob_idx]\n",
    "\n",
    "y_test_partition_pred_proba = fair_where_model.predict(\n",
    "    X_test, batch_size=BATCH_SIZE\n",
    ")[:, pos_class_prob_idx]\n",
    "\n",
    "train_preds_partition_df = pd.DataFrame(\n",
    "    {\"pred\": class_y_train_pred_partition, \"prob\": y_train_partition_pred_proba}\n",
    ")\n",
    "\n",
    "val_preds_partition_df = pd.DataFrame(\n",
    "    {\"pred\": class_y_val_pred_partition, \"prob\": y_val_partition_pred_proba}\n",
    ")\n",
    "\n",
    "test_preds_partition_df = pd.DataFrame(\n",
    "    {\"pred\": class_y_test_pred_partition, \"prob\": y_test_partition_pred_proba}\n",
    ")\n",
    "\n",
    "train_preds_partition_df.to_csv(\n",
    "    f\"{results_path}{dataset_name}_{fair_notion}_where_model_train_pred.csv\",\n",
    "    index=False,\n",
    ")\n",
    "val_preds_partition_df.to_csv(\n",
    "    f\"{results_path}{dataset_name}_{fair_notion}_where_model_val_pred.csv\",\n",
    "    index=False,\n",
    ")\n",
    "test_preds_partition_df.to_csv(\n",
    "    f\"{results_path}{dataset_name}_{fair_notion}_where_model_test_pred.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Optimization Correction Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data for other spatial bias mitigation models\n",
    "val_pred_base_df = pd.read_csv(f\"{prediction_dir}val_{prediction_name}.csv\")\n",
    "val_pred_partition_df = pd.read_csv(\n",
    "    f\"{results_path}{dataset_name}_{fair_notion}_where_model_val_pred.csv\"\n",
    ")\n",
    "y_val_df = pd.read_csv(f\"{preprocess_dir}y_val_{dataset_name}.csv\")\n",
    "y_val = get_y(y_val_df, \"label\")\n",
    "pts_per_region_val_df = read_scanned_regs(\n",
    "    f\"{partitioning_dir}val_{partioning_name}.csv\"\n",
    ")\n",
    "pts_per_region_val = pts_per_region_val_df[\"points\"].tolist()\n",
    "y_val_pred_base = get_y(val_pred_base_df, \"pred\")\n",
    "y_val_base_pred_proba = get_y(val_pred_base_df, \"prob\")\n",
    "y_val_pred_partition = get_y(val_pred_partition_df, \"pred\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Maximum Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fair_notion == \"equal_opportunity\":\n",
    "    # Get positive class information to consider equal opportunity\n",
    "    pos_val_y_true_indices, _ = get_pos_info_regions(y_val, pts_per_region_val)\n",
    "    pos_val_y_pred_base = y_val_pred_base[pos_val_y_true_indices]\n",
    "    pos_y_val_pred_partition = y_val_pred_partition[pos_val_y_true_indices]\n",
    "\n",
    "# Calculate the differences between the base and partition model\n",
    "# to use it as budget for the mitigation models\n",
    "base_partition_diffs = (\n",
    "    np.sum(np.abs(y_val_pred_base - y_val_pred_partition))\n",
    "    if fair_notion == \"statistical_parity\"\n",
    "    else np.sum((np.abs(pos_val_y_pred_base - pos_y_val_pred_partition)))\n",
    ")\n",
    "print(\"\\nDifferences between base and partition in validation set:\")\n",
    "print(\"Number of different elements:\", base_partition_diffs)\n",
    "n_flips = base_partition_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the PROMIS methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlimit=300#3600\n",
    "max_pr_shift=0.1\n",
    "promis_methods = [\n",
    "    \"promis_app\",\n",
    "    \"promis_opt\",\n",
    "]\n",
    "\n",
    "for method in promis_methods:\n",
    "    fair_model = SpatialOptimFairnessModel(method)\n",
    "    fair_model.multi_fit(\n",
    "        points_per_region=pts_per_region_val,\n",
    "        n_flips_start = n_flips_start,\n",
    "        step=n_flips_start,\n",
    "        n_flips=n_flips,\n",
    "        y_pred=y_val_pred_base,\n",
    "        y_true=y_val if fair_notion == \"equal_opportunity\" else None,\n",
    "        y_pred_probs=y_val_base_pred_proba,\n",
    "        wlimit=wlimit,\n",
    "        fair_notion=fair_notion,\n",
    "        overlap=overlap,\n",
    "        no_of_threads=0,\n",
    "        verbose=1,\n",
    "        max_pr_shift=max_pr_shift\n",
    "    )\n",
    "\n",
    "    if method == \"promis_opt\":\n",
    "        model_save_file = f\"{sp_opt_models_dir}/{method}_wlimit_{wlimit}.pkl\"\n",
    "    else:\n",
    "        model_save_file = f\"{sp_opt_models_dir}/{method}.pkl\"\n",
    "\n",
    "    fair_model.save_model(model_save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Spatial Flip Method (Only for Statistical Parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    }
   ],
   "source": [
    "# We apply Spatial Flip Model directly on the test set\n",
    "\n",
    "if fair_notion == \"statistical_parity\":\n",
    "    # read data for other spatial bias mitigation models\n",
    "    test_pred_base_df = pd.read_csv(f\"{prediction_dir}test_{prediction_name}.csv\")\n",
    "    pts_per_region_test_df = read_scanned_regs(\n",
    "        f\"{partitioning_dir}test_{partioning_name}.csv\"\n",
    "    )\n",
    "    pts_per_region_test = pts_per_region_test_df[\"points\"].tolist()\n",
    "    y_test_pred_base = get_y(test_pred_base_df, \"pred\")\n",
    "\n",
    "\n",
    "    fair_model = SpatialFlipFairnessModel(\"iter\")\n",
    "    fair_model.multi_fit(\n",
    "        points_per_region=pts_per_region_test,\n",
    "        n_flips_start=n_flips_start,\n",
    "        step=n_flips_start,\n",
    "        n_flips=n_flips,\n",
    "        y_pred=y_test_pred_base,\n",
    "        overlap=overlap,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    fair_model.save_model(\n",
    "        f\"{sp_flip_models_dir}/iter.pkl\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO8gqPzfYENP1b5eS/AbDTx",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show PROMIS Approximation application in an unfair by design semi-syntehtic dataset, where the audit regions are in total 8 generated from KMeans. \n",
    "\n",
    "We show through visualizations the initial spatial bias and the results of the mitigation proccess by using the PROMIS approach to apply direct flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "\n",
    "from methods.models.optimization_model import SpatialOptimFairnessModel\n",
    "from utils.data_utils import read_scanned_regs, get_y\n",
    "from utils.results_names_utils import combine_world_info, get_train_val_test_paths\n",
    "import pandas as pd\n",
    "from utils.scores import get_mlr, get_fair_stat_ratios\n",
    "from utils.stats_utils import  get_signif_threshold\n",
    "from utils.plot_utils import plot_map_with_polygons\n",
    "from utils.plot_utils import plot_fairness_map\n",
    "import numpy as np\n",
    "from utils.geo_utils import compute_polygons, filterbbox\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "base_path = \"../data/\"\n",
    "clf_name = \"semi_synthetic_regions_non_overlap_k_8\"\n",
    "dataset_name = \"crime\"\n",
    "partioning_type_name = \"non_overlap_k_8\"\n",
    "fairness_notion = \"statistical_parity\"\n",
    "\n",
    "\n",
    "results = {}\n",
    "res_desc_label, partioning_name, prediction_name = combine_world_info(\n",
    "    dataset_name, partioning_type_name, clf_name\n",
    ")\n",
    "_, val_path_info, test_path_info = get_train_val_test_paths(\n",
    "    base_path, partioning_name, prediction_name, dataset_name\n",
    ")\n",
    "test_regions_df = read_scanned_regs(test_path_info[\"regions\"])\n",
    "test_pred_df = pd.read_csv(test_path_info[\"predictions\"])\n",
    "y_pred_test = get_y(test_pred_df, \"pred\")\n",
    "test_fair_pred_df = pd.read_csv(f\"{base_path}predictions/test_fair_pred_semi_synthetic_{partioning_name}.csv\")\n",
    "y_pred_fair_test = get_y(test_fair_pred_df, \"pred\")\n",
    "test_points_per_region = test_regions_df[\"points\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the initial statistics of the fair (using binomial with positive rate=0.8 to generate predictions) model\n",
    "init_N = len(y_pred_fair_test)\n",
    "init_P = np.sum(y_pred_fair_test)\n",
    "init_PR = init_P / init_N\n",
    "print(f'N={init_N} points')\n",
    "print(f'P={init_P} positives') #positives being 'serious crimes' == 1 and negative class: 'non-serious' crimes = 0 (predicted by RF classifier)\n",
    "print(f'PR={init_PR:.3f}')\n",
    "test_pred_df.head()\n",
    "\n",
    "init_mlr_test, init_stats_test = get_mlr(y_pred_fair_test, test_points_per_region, True)\n",
    "test_regions_df['init_stat'] = init_stats_test\n",
    "signif_thresh_test_init = get_signif_threshold(0.005, 400, [{\"points\": pts} for pts in test_points_per_region], init_N, init_P, seed=42)\n",
    "signif_regs_indices_test_init = [i for i, stat in enumerate(init_stats_test) if stat >= signif_thresh_test_init]\n",
    "print(f\"Test MLR (Equal Opportunity): {init_mlr_test:.3f}\")\n",
    "print(f\"Total Significant Regions: {len(signif_regs_indices_test_init)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the statistics of th unfair by design model\n",
    "N = len(y_pred_test)\n",
    "P = np.sum(y_pred_test)\n",
    "PR = init_P / init_N\n",
    "print(f'N={N} points')\n",
    "print(f'P={P} positives') #positives being 'serious crimes' == 1 and negative class: 'non-serious' crimes = 0 (predicted by RF classifier)\n",
    "print(f'PR={PR:.3f}')\n",
    "test_pred_df.head()\n",
    "\n",
    "mlr_test, stats_test = get_mlr(y_pred_test, test_points_per_region, True)\n",
    "test_regions_df['stat'] = stats_test\n",
    "signif_thresh_test = get_signif_threshold(0.005, 400, [{\"points\": pts} for pts in test_points_per_region], N, P, seed=42)\n",
    "signif_regs_indices_test = [i for i, stat in enumerate(stats_test) if stat >= signif_thresh_test]\n",
    "print(f\"Test MLR (Equal Opportunity): {mlr_test:.3f}\")\n",
    "print(f\"Total Significant Regions: {len(signif_regs_indices_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine bounding box for display to avoid plotting outliers\n",
    "bbox_min_lon=-118.6673\n",
    "bbox_min_lat=33.707\n",
    "bbox_max_lon=-118.16\n",
    "bbox_max_lat=34.3374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the statistics of the unfair by design model\n",
    "test_regions_df['pr'] = test_regions_df['points'].apply(lambda pts: sum(y_pred_test[pts])/len(pts) if len(pts) > 0 else 0)\n",
    "PR_test = sum(y_pred_test)/len(y_pred_test)\n",
    "\n",
    "test_regions_df[\"fair_stat_ratio\"], max_stat_test = get_fair_stat_ratios(\n",
    "    test_regions_df[\"stat\"].to_numpy(),\n",
    "    test_regions_df[\"pr\"].to_numpy(),\n",
    "    PR_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the initial statistics of the fair model \n",
    "test_regions_df['init_pr'] = test_regions_df['points'].apply(lambda pts: sum(y_pred_fair_test[pts])/len(pts) if len(pts) > 0 else 0)\n",
    "PR_test_init = sum(y_pred_fair_test)/len(y_pred_fair_test)\n",
    "\n",
    "test_regions_df[\"init_fair_stat_ratio\"], _ = get_fair_stat_ratios(\n",
    "    test_regions_df[\"init_stat\"].to_numpy(),\n",
    "    test_regions_df[\"init_pr\"].to_numpy(),\n",
    "    PR_test_init,\n",
    "    max_stat=max_stat_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the coordinates inside the bounding box for display\n",
    "\n",
    "sub_df = test_pred_df.copy()\n",
    "\n",
    "sub_df = filterbbox(sub_df, bbox_min_lon, bbox_min_lat, bbox_max_lon, bbox_max_lat)\n",
    "sub_test_regions_df = test_regions_df.copy()\n",
    "set_new_pts = set(sub_df.index.tolist())\n",
    "sub_test_regions_df['points'] = sub_test_regions_df['points'].apply(lambda pts: list(set(pts) & set_new_pts))\n",
    "\n",
    "old_2_new_idx = {}\n",
    "for i, ind in enumerate(sub_df.index):\n",
    "    old_2_new_idx[ind] = i\n",
    "\n",
    "sub_df = sub_df.reset_index()\n",
    "sub_test_regions_df['points'] = sub_test_regions_df['points'].apply(lambda pts: [old_2_new_idx[p] for p in pts])\n",
    "sub_test_regions_df = compute_polygons(sub_test_regions_df, sub_df)\n",
    "\n",
    "y_pred_test_sub = get_y(sub_df, \"pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the normalized LR of the fair by design world\n",
    "plot_fairness_map(\n",
    "    regs_df_list=[sub_test_regions_df],\n",
    "    title=\"Initial Fair by Design Predictions - Normalized LR\",\n",
    "    score_label=\"init_fair_stat_ratio\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get flips done ot create the unfair by design model \n",
    "pos_to_neg_pts  = np.where((y_pred_test != y_pred_fair_test) & (y_pred_fair_test == 1))[0]\n",
    "neg_to_pos_pts  = np.where((y_pred_test != y_pred_fair_test) & (y_pred_fair_test == 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep flips in the bounding box\n",
    "sub_pos_to_neg_pts = []\n",
    "for i, pt in enumerate(pos_to_neg_pts):\n",
    "    if pt in sub_df['index'].values:\n",
    "        sub_pos_to_neg_pts.append(sub_df[sub_df['index'] == pt].index[0])\n",
    "\n",
    "sub_neg_to_pos_pts = []\n",
    "for i, pt in enumerate(neg_to_pos_pts):\n",
    "    if pt in sub_df['index'].values:\n",
    "        sub_neg_to_pos_pts.append(sub_df[sub_df['index'] == pt].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Flips done ot create the unfair by design model while keeping the initial positive rate\n",
    "plot_map_with_polygons(\n",
    "    df=sub_df,\n",
    "    regs_df_list=[sub_test_regions_df],\n",
    "    other_idxs=[sub_pos_to_neg_pts, sub_neg_to_pos_pts],\n",
    "    other_colors=[\"orange\", \"green\"],\n",
    "    regs_color_list=[\"#0000FF\"],\n",
    "    title=\"Flips to Produce Unfair by Design Predictions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the normalized LR of the unfair by design world\n",
    "plot_fairness_map(\n",
    "    regs_df_list=[sub_test_regions_df],\n",
    "    title=\"Unfair by Design Predictions - Normalized LR\",\n",
    "    score_label=\"fair_stat_ratio\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the regions and the points of the unfair by design world\n",
    "plot_map_with_polygons(\n",
    "    df=sub_df,\n",
    "    y_pred=y_pred_test_sub,\n",
    "    regs_df_list=[sub_test_regions_df],\n",
    "    regs_color_list=[\"#0000FF\"],\n",
    "    title=\"Regions - Points - Unfair by Design Predictions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 29610 # the budget used to make the world unfair startint from the initial fair world\n",
    "no_of_threads=0\n",
    "fair_model = SpatialOptimFairnessModel(\"promis_app\") # use PROMIS Approximation\n",
    "fair_model.multi_fit(\n",
    "    points_per_region=test_points_per_region,\n",
    "    n_flips_start = budget,\n",
    "    step=10,\n",
    "    n_flips=budget,\n",
    "    y_pred=y_pred_test,\n",
    "    wlimit=300,\n",
    "    fair_notion=fairness_notion,\n",
    "    overlap=True,\n",
    "    init_threshold=None,\n",
    "    no_of_threads=no_of_threads,\n",
    "    verbose=1,\n",
    "    max_pr_shift=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the points to flip and respective flip directions\n",
    "\n",
    "pts_to_change_sol = fair_model.budget_to_solution_info[budget][\"pts_to_change_sol\"]\n",
    "pts_to_change = fair_model.budget_to_solution_info[budget][\"pts_to_change\"]\n",
    "\n",
    "# Keep only the points that are in the bounding box for display\n",
    "\n",
    "sub_pts_to_change_sol_indices = []\n",
    "sub_pts_to_change = []\n",
    "for i, pt in enumerate(pts_to_change):\n",
    "    if pt in sub_df['index'].values:\n",
    "        sub_pts_to_change.append(sub_df[sub_df['index'] == pt].index[0])\n",
    "        sub_pts_to_change_sol_indices.append(i)\n",
    "\n",
    "sub_pts_to_change_sol_indices = np.array(sub_pts_to_change_sol_indices)\n",
    "sub_pts_to_change_sol = np.array(pts_to_change_sol)[sub_pts_to_change_sol_indices]\n",
    "\n",
    "sub_pts_to_change = np.array(sub_pts_to_change)\n",
    "\n",
    "pts_to_change_sol_neg = np.where(sub_pts_to_change_sol == -1)[0]\n",
    "pts_to_change_sol_pos = np.where(sub_pts_to_change_sol == 1)[0]\n",
    "\n",
    "pts_to_change_neg = sub_pts_to_change[pts_to_change_sol_neg]\n",
    "pts_to_change_pos = sub_pts_to_change[pts_to_change_sol_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Flips to make the world fair\n",
    "plot_map_with_polygons(\n",
    "    df=sub_df,\n",
    "    regs_df_list=[sub_test_regions_df],\n",
    "    other_idxs=[pts_to_change_neg, pts_to_change_pos],\n",
    "    other_colors=[\"orange\", \"green\"],\n",
    "    regs_color_list=[\"#0000FF\"],\n",
    "    title=\"Flips to Mitigate Spatial Bias\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the new predictions after the applying the flips\n",
    "test_new_preds = fair_model.multi_predict(test_points_per_region, y_pred_test, apply_fit_flips=True)\n",
    "test_new_preds = test_new_preds[budget]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the new statistics\n",
    "N_test_new = len(test_new_preds)\n",
    "P_test_new = np.sum(test_new_preds)\n",
    "PR_test_new = P_test_new/N_test_new\n",
    "print(f'N={N_test_new} points')\n",
    "print(f'P={P_test_new} positives') #positives being 'serious crimes' == 1 and negative class: 'non-serious' crimes = 0 (predicted by RF classifier)\n",
    "print(f'PR={PR_test_new} positives rate')\n",
    "\n",
    "mlr_test, stats_test = get_mlr(test_new_preds, test_points_per_region, True)\n",
    "test_regions_df['new_stat'] = stats_test\n",
    "signif_thresh_test_init = get_signif_threshold(0.005, 400, [{\"points\": pts} for pts in test_points_per_region], N_test_new, P_test_new, seed=42)\n",
    "signif_regs_indices_test = [i for i, stat in enumerate(stats_test) if stat >= signif_thresh_test_init]\n",
    "print(f\"Test MLR (Equal Opportunity): {mlr_test:.3f}\")\n",
    "print(f\"Total Significant Regions: {len(signif_regs_indices_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the positive rate for each region and the new normalized LR\n",
    "test_regions_df['new_pr'] = test_regions_df['points'].apply(lambda pts: sum(test_new_preds[pts])/len(pts))\n",
    "PR_test_new = sum(test_new_preds)/len(test_new_preds)\n",
    "\n",
    "test_regions_df[\"new_fair_stat_ratio\"], _ = get_fair_stat_ratios(\n",
    "    test_regions_df[\"new_stat\"].to_numpy(),\n",
    "    test_regions_df[\"new_pr\"].to_numpy(),\n",
    "    PR_test_new,\n",
    "    max_stat_test\n",
    ")\n",
    "test_regions_df['new_fair_stat_ratio'] = test_regions_df[\"new_fair_stat_ratio\"]\n",
    "sub_test_regions_df['new_fair_stat_ratio'] = test_regions_df[\"new_fair_stat_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_regions_df[['init_pr', 'pr', \"new_pr\", \"init_fair_stat_ratio\", \"fair_stat_ratio\", \"new_fair_stat_ratio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sub population of the predictions which are in the bbox to display\n",
    "sub_test_new_preds_indices = list(set(list(range(len(test_new_preds)))) & set(sub_df['index'].values))\n",
    "sub_test_new_preds = test_new_preds[sub_test_new_preds_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the new regions and the points of the mitigated predictions\n",
    "plot_map_with_polygons(\n",
    "    df=sub_df,\n",
    "    y_pred=sub_test_new_preds,\n",
    "    regs_df_list=[sub_test_regions_df],\n",
    "    regs_color_list=[\"#0000FF\"],\n",
    "    title=\"Regions - Points - Mitigated Predictions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the normalized LR of the mitigated predictions\n",
    "plot_fairness_map(\n",
    "    regs_df_list=[sub_test_regions_df],\n",
    "    title=\"Mitigated Predictions - Normalized LR\",\n",
    "    score_label=\"new_fair_stat_ratio\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promis_env_new",
   "language": "python",
   "name": "promis_env_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to show the times and metrics for the final budget. You may run this notebook after running all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"final_budget_metrics.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and process the final budget metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_budget_metrics_df = pd.read_csv(fname)\n",
    "\n",
    "audit_regions_name_dict = {\n",
    "    \"Non-Overlapping KMeans\": \"Clusters\",\n",
    "    \"Overlapping KMeans\": \"Scan Regions\",\n",
    "    \"Overlapping Partitionings\": \"Grids\",\n",
    "}\n",
    "fairness_notion_name_dict = {\n",
    "    \"Equal Opportunity\": \"EO\",\n",
    "    \"Statistical Parity\": \"SP\",\n",
    "}\n",
    "final_budget_metrics_df[\"Audit Regions\"] = final_budget_metrics_df[\"Audit Regions\"].map(\n",
    "    audit_regions_name_dict\n",
    ")\n",
    "final_budget_metrics_df[\"Fairness Notion\"] = final_budget_metrics_df[\n",
    "    \"Fairness Notion\"\n",
    "].map(fairness_notion_name_dict)\n",
    "\n",
    "# combine experiment columns info to create unique ids for each experiment\n",
    "final_budget_metrics_df[\"exp_desc\"] = (\n",
    "    final_budget_metrics_df[\"Dataset\"]\n",
    "    + \"_\"\n",
    "    + final_budget_metrics_df[\"Classifier\"]\n",
    "    + \"_\"\n",
    "    + final_budget_metrics_df[\"Audit Regions\"]\n",
    "    + \"_\"\n",
    "    + final_budget_metrics_df[\"Fairness Notion\"]\n",
    ")\n",
    "# remove the results of the Promis-Exact method with high work limit\n",
    "final_budget_metrics_df = final_budget_metrics_df[\n",
    "    final_budget_metrics_df[\"Method\"].isin(['init', 'promis_opt_wlimit_300', 'promis_app', 'FairWhere', 'iter'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    \"init\",\n",
    "    \"iter\",\n",
    "    \"promis_opt_wlimit_300\",\n",
    "    \"promis_app\",\n",
    "    \"FairWhere\",\n",
    "]\n",
    "\n",
    "final_res = {\n",
    "    \"Dataset\": [],\n",
    "    \"Classifier\": [],\n",
    "    \"Audit Regions\": [],\n",
    "    \"Fairness\": [],\n",
    "    \"Budget\": [],\n",
    "    \"Init SBI\": [],\n",
    "    \"PROMIS-Direct SBI\": [],\n",
    "    \"PROMIS-Approx SBI\": [],\n",
    "    \"FairWhere SBI\": [],\n",
    "    \"SpatialFlip SBI\": [],\n",
    "    \"Init MeanDev\": [],\n",
    "    \"PROMIS-Direct MeanDev\": [],\n",
    "    \"PROMIS-Approx MeanDev\": [],\n",
    "    \"FairWhere MeanDev\": [],\n",
    "    \"SpatialFlip MeanDev\": [],\n",
    "    \"PROMIS-Direct Time\": [],\n",
    "    \"PROMIS-Approx Time\": [],\n",
    "    \"FairWhere Time\": [],\n",
    "    \"SpatialFlip Time\": [],\n",
    "    \"Init Accuracy\": [],\n",
    "    \"PROMIS-Direct Accuracy\": [],\n",
    "    \"PROMIS-Approx Accuracy\": [],\n",
    "    \"FairWhere Accuracy\": [],\n",
    "    \"SpatialFlip Accuracy\": [],\n",
    "    \"Init F1\": [],\n",
    "    \"PROMIS-Direct F1\": [],\n",
    "    \"PROMIS-Approx F1\": [],\n",
    "    \"FairWhere F1\": [],\n",
    "    \"SpatialFlip F1\": [],\n",
    "}\n",
    "methods_to_labels = {\n",
    "    'init': \"Init\", \n",
    "    'iter': \"SpatialFlip\", \n",
    "    'promis_opt_wlimit_300': \"PROMIS-Direct\", \n",
    "    'promis_app': \"PROMIS-Approx\", \n",
    "    'FairWhere': \"FairWhere\"\n",
    "}\n",
    "\n",
    "# fill in the final results dataframe\n",
    "for exp_desc in final_budget_metrics_df['exp_desc'].unique():\n",
    "    exp_df = final_budget_metrics_df[final_budget_metrics_df['exp_desc'] == exp_desc]\n",
    "    final_res[\"Dataset\"].append(exp_df['Dataset'].values[-1])\n",
    "    final_res[\"Classifier\"].append(exp_df['Classifier'].values[-1])\n",
    "    final_res[\"Audit Regions\"].append(exp_df['Audit Regions'].values[-1])\n",
    "    final_res[\"Fairness\"].append(exp_df['Fairness Notion'].values[-1])\n",
    "    final_res[\"Budget\"].append(exp_df['Budget'].values[-1])\n",
    "    for method in methods:\n",
    "        method_df = exp_df[exp_df['Method'] == method]\n",
    "        \n",
    "        for metric in [\"Time\", \"SBI\", \"MeanDev\", \"Accuracy\", \"F1\"]:\n",
    "            label = methods_to_labels[method] + \" \" + metric\n",
    "            if method_df.empty:\n",
    "                final_res[label].append(None)\n",
    "            else:\n",
    "                if metric == \"Time\":\n",
    "                    if method != \"init\":\n",
    "                        final_res[label].append(method_df[\"Time\"].values[0])\n",
    "                else:\n",
    "                    final_res[label].append(method_df[metric].values[0])\n",
    "            \n",
    "final_res_df = pd.DataFrame(final_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the results for each set of experiments\n",
    "\n",
    "DNN_sbi_exp_df = final_res_df[final_res_df['Classifier'] == 'DNN'][[\"Audit Regions\", \"Fairness\", \"Budget\", \"Init SBI\", \"PROMIS-Direct SBI\", \"PROMIS-Approx SBI\", \"FairWhere SBI\", \"SpatialFlip SBI\"]]\n",
    "DNN_mean_disparity_exp_df = final_res_df[final_res_df['Classifier'] == 'DNN'][[\"Audit Regions\", \"Fairness\", \"Budget\", \"Init MeanDev\", \"PROMIS-Direct MeanDev\", \"PROMIS-Approx MeanDev\", \"FairWhere MeanDev\", \"SpatialFlip MeanDev\"]]\n",
    "DNN_f1_exp_df = final_res_df[final_res_df['Classifier'] == 'DNN'][[\"Audit Regions\", \"Fairness\", \"Budget\", \"Init F1\", \"PROMIS-Direct F1\", \"PROMIS-Approx F1\", \"FairWhere F1\", \"SpatialFlip F1\"]]\n",
    "DNN_times_df = final_res_df[final_res_df['Classifier'] == 'DNN'][[\"Audit Regions\", \"Fairness\", \"Budget\", \"PROMIS-Direct Time\", \"PROMIS-Approx Time\", \"FairWhere Time\", \"SpatialFlip Time\"]]\n",
    "\n",
    "LAR_sbi_exp_df = final_res_df[final_res_df['Dataset'] == 'LAR'][[\"Audit Regions\", \"Budget\", \"Init SBI\", \"PROMIS-Direct SBI\", \"PROMIS-Approx SBI\", \"SpatialFlip SBI\"]]\n",
    "LAR_times_df = final_res_df[final_res_df['Dataset'] == 'LAR'][[\"Audit Regions\", \"Budget\", \"PROMIS-Direct Time\", \"PROMIS-Approx Time\", \"SpatialFlip Time\"]]\n",
    "\n",
    "synth_sbi_exp_df = final_res_df[final_res_df['Classifier'] == 'Unfair by Design'][[\"Audit Regions\", \"Budget\", \"Init SBI\", \"PROMIS-Direct SBI\", \"PROMIS-Approx SBI\", \"SpatialFlip SBI\"]]\n",
    "synth_times_df = final_res_df[final_res_df['Classifier'] == 'Unfair by Design'][[\"Audit Regions\", \"Budget\", \"PROMIS-Direct Time\", \"PROMIS-Approx Time\", \"SpatialFlip Time\"]]\n",
    "\n",
    "XGB_sbi_exp_df = final_res_df[final_res_df['Classifier'] == 'XGB'][[\"Audit Regions\", \"Budget\", \"Init SBI\", \"PROMIS-Direct SBI\", \"PROMIS-Approx SBI\"]]\n",
    "XGB_acc_exp_df = final_res_df[final_res_df['Classifier'] == 'XGB'][[\"Audit Regions\", \"Budget\", \"Init Accuracy\", \"PROMIS-Direct Accuracy\", \"PROMIS-Approx Accuracy\"]]\n",
    "XGB_times_df = final_res_df[final_res_df['Classifier'] == 'XGB'][[\"Audit Regions\", \"Budget\", \"PROMIS-Direct Time\", \"PROMIS-Approx Time\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Times for All Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_round(x):\n",
    "    if isinstance(x, (int, float)):  \n",
    "        return str(int(round(x))) if x >= 1 else str(round(x, 2))\n",
    "    return x  \n",
    "times = final_res_df[[\"Dataset\",\"Audit Regions\", \"Classifier\", \"Fairness\", 'PROMIS-Direct Time', 'PROMIS-Approx Time', 'FairWhere Time',\n",
    "       'SpatialFlip Time'\t]].copy()\n",
    "times.fillna(\"-\", inplace=True)\n",
    "numeric_columns = ['PROMIS-Direct Time', 'PROMIS-Approx Time', 'FairWhere Time', 'SpatialFlip Time']\n",
    "times[numeric_columns] = times[numeric_columns].applymap(custom_round)\n",
    "\n",
    "display(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Metrics for each set of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DNN SBI\")\n",
    "display(DNN_sbi_exp_df)\n",
    "\n",
    "print(\"DNN MeanDev\")\n",
    "display(DNN_mean_disparity_exp_df)\n",
    "\n",
    "print(\"DNN F1\")\n",
    "display(DNN_f1_exp_df)\n",
    "\n",
    "print(\"DNN Times\")\n",
    "display(DNN_times_df)\n",
    "\n",
    "print(\"LAR SBI\")\n",
    "display(LAR_sbi_exp_df)\n",
    "\n",
    "print(\"LAR Times\")\n",
    "display(LAR_times_df)\n",
    "\n",
    "print(\"Synth SBI\")\n",
    "display(synth_sbi_exp_df)\n",
    "\n",
    "print(\"Synth Times\")\n",
    "display(synth_times_df)\n",
    "\n",
    "print(\"XGB SBI\")\n",
    "display(XGB_sbi_exp_df)\n",
    "\n",
    "print(\"XGB Accuracy\")\n",
    "display(XGB_acc_exp_df)\n",
    "\n",
    "print(\"XGB Times\")\n",
    "display(XGB_times_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PROMIS Env",
   "language": "python",
   "name": "promis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
